{
 "metadata": {
  "name": "",
  "signature": "sha256:d545f3437864eccb5dcde8f3d70d64407f78466bc05dfd3f871fb5b94c1f011d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Class 08 - Bayes - Lab Naive Bayes Classification"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Readings\n",
      "# http://scikit-learn.org/stable/modules/naive_bayes.html\n",
      "# http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import data\n",
      "critics = pd.read_csv('/home/vagrant/notebooks/fall_2014_lessons/datasets/rt_critics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>imdb</th>\n",
        "      <th>rtid</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>   14072.000000</td>\n",
        "      <td> 1.407200e+04</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>  155048.688104</td>\n",
        "      <td> 5.594059e+07</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  157531.635841</td>\n",
        "      <td> 1.805150e+08</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   13442.000000</td>\n",
        "      <td> 1.100000e+01</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   97240.000000</td>\n",
        "      <td> 1.129200e+04</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>  115798.000000</td>\n",
        "      <td> 1.337500e+04</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>  134119.000000</td>\n",
        "      <td> 1.645000e+04</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 1190539.000000</td>\n",
        "      <td> 7.710318e+08</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "                 imdb          rtid\n",
        "count    14072.000000  1.407200e+04\n",
        "mean    155048.688104  5.594059e+07\n",
        "std     157531.635841  1.805150e+08\n",
        "min      13442.000000  1.100000e+01\n",
        "25%      97240.000000  1.129200e+04\n",
        "50%     115798.000000  1.337500e+04\n",
        "75%     134119.000000  1.645000e+04\n",
        "max    1190539.000000  7.710318e+08"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sample look at data\n",
      "critics.quote[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'A winning animated feature that has something for everyone on the age spectrum.'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Multinomial vs Bernoulli Models\n",
      "\n",
      "# The Multinomial model actually counts occurences out of all \n",
      "# possible occurences for probability - better for greater features\n",
      "\n",
      "# The Bernoulli model counts only all documents with presence \n",
      "#of the word - better for fewer features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import BernoulliNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# How the Count Vectorizer Works"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's start with a simple example of 3 \"reviews\" of math..\n",
      "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
      "print \"Original text:\\n\\t\", '\\n\\t'.join(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original text:\n",
        "\tMath is great\n",
        "\tMath is really great\n",
        "\tExciting exciting Math\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ngram_range : tuple (min_n, max_n)\n",
      "\n",
      "# The lower and upper boundary of the range of n-values for\n",
      "# different n-grams to be extracted. \n",
      "\n",
      "# All values of n such that min_n <= n <= max_n will be used.\n",
      "\n",
      "vectorizer = CountVectorizer(ngram_range=(1,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call \"fit\" to build the vocabulary\n",
      "vectorizer.fit(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
        "  VisibleDeprecationWarning)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What is an ngram?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# display the names of the features (n gram)\n",
      "# remember, we set the ngram_range=(1,2)\n",
      "\n",
      "vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[u'exciting',\n",
        " u'exciting exciting',\n",
        " u'exciting math',\n",
        " u'great',\n",
        " u'is',\n",
        " u'is great',\n",
        " u'is really',\n",
        " u'math',\n",
        " u'math is',\n",
        " u'really',\n",
        " u'really great']"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# still not clear how the words became tokenized into \n",
      "# a 3x11 sparse matrix..?!!!\u00ac"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call transform to convert text to a bag of words\n",
      "# sparse matrix transformation\n",
      "# A sparse matrix is a matrix that allows special techniques to take \n",
      "# advantage of the large number of \"background\" (commonly zero) elements.\n",
      "\n",
      "x = vectorizer.transform(text)\n",
      "\n",
      "#<3x11 sparse matrix of type '<type 'numpy.int64'>'\n",
      "#with 16 stored elements in Compressed Sparse Row format>\n",
      "x\n",
      "\n",
      "# the array before transformation\n",
      "#X is a (nreview, nwords) array.  each row corresponds to a \n",
      "#bag of words representation for a single review.  this will \n",
      "#input to the model\n",
      "print x.toarray()  \n",
      "\n",
      "# transformed as sparse matrix.. for optimal storage..\n",
      "# how this is done is loop through the matrix, and record the \n",
      "# (i,j) location of each non zero element, and then the element itself\n",
      "\n",
      "#i.e.  the \"2\" is located at (i = 2, j = 0).. zero indexing\n",
      "print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 0 0 ..., 0 0 0]\n",
        " [0 0 0 ..., 0 0 0]\n",
        " [0 0 0 ..., 0 0 0]]\n",
        "  (0, 59210)\t1\n",
        "  (0, 72313)\t1\n",
        "  (0, 72913)\t1\n",
        "  (0, 86476)\t1\n",
        "  (1, 59210)\t1\n",
        "  (1, 72313)\t1\n",
        "  (1, 73450)\t1\n",
        "  (1, 86476)\t1\n",
        "  (1, 113798)\t1\n",
        "  (2, 46375)\t2\n",
        "  (2, 86476)\t1\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's go back to the Rotten Tomatoes Example\n",
      "\n",
      "# Use text reviews to predict if the reviewer will rate the movie as\n",
      "# Rotten or Fresh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Preparing our Features (X) and Target (Y) for Training\n",
      "\n",
      "#X is a (nreview, nwords) array.  each row corresponds to a \n",
      "#bag of words representation for a single review.  this will \n",
      "#input to the model\n",
      "\n",
      "# Y is nrview-element 1/0 array.. enconding whether a review is \n",
      "# \"fresh\" (1) or \"rotten\" (0).  this is the desired output\n",
      "\n",
      "# this means that we are trying to use the text in the review to \n",
      "# try to predict how that reviewer will score the rating \"fresh\"/\"rotten\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate the vectorizer with n-gram of length one or two\n",
      "vectorizer = CountVectorizer(ngram_range = (1,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call \"fit\" to build the vocabulary\n",
      "# critics is the imported dataset for rotten tomatoes\n",
      "# quote is where the reviews are, under the critics dataset\n",
      "vectorizer.fit(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this shows the ngrams of 1 and 2 created\n",
      "# notice that there is a fair share of gibberish and/or null values\n",
      "\n",
      "vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "[u'000',\n",
        " u'000 000',\n",
        " u'000 and',\n",
        " u'000 leagues',\n",
        " u'000 looks',\n",
        " u'000 page',\n",
        " u'000 to',\n",
        " u'0014',\n",
        " u'0014 or',\n",
        " u'007',\n",
        " u'007 adventure',\n",
        " u'007 but',\n",
        " u'007 capers',\n",
        " u'007 formula',\n",
        " u'007 is',\n",
        " u'007 not',\n",
        " u'007 one',\n",
        " u'007 was',\n",
        " u'07',\n",
        " u'10',\n",
        " u'10 beats',\n",
        " u'10 best',\n",
        " u'10 but',\n",
        " u'10 collaborations',\n",
        " u'10 directors',\n",
        " u'10 gallon',\n",
        " u'10 greatest',\n",
        " u'10 it',\n",
        " u'10 million',\n",
        " u'10 minute',\n",
        " u'10 minutes',\n",
        " u'10 motion',\n",
        " u'10 romantic',\n",
        " u'10 seconds',\n",
        " u'10 sentences',\n",
        " u'10 short',\n",
        " u'10 there',\n",
        " u'10 things',\n",
        " u'10 times',\n",
        " u'10 year',\n",
        " u'10 years',\n",
        " u'100',\n",
        " u'100 ft',\n",
        " u'100 miles',\n",
        " u'100 million',\n",
        " u'100 minutes',\n",
        " u'100 of',\n",
        " u'100 per',\n",
        " u'100 percent',\n",
        " u'100 plus',\n",
        " u'100 to',\n",
        " u'101',\n",
        " u'101 course',\n",
        " u'101 domestic',\n",
        " u'101 minutes',\n",
        " u'102',\n",
        " u'102 minute',\n",
        " u'104',\n",
        " u'104 very',\n",
        " u'105',\n",
        " u'105 minutes',\n",
        " u'108',\n",
        " u'108 minutes',\n",
        " u'10th',\n",
        " u'10th century',\n",
        " u'10th reunion',\n",
        " u'11',\n",
        " u'11 anxiety',\n",
        " u'11 crowd',\n",
        " u'11 songs',\n",
        " u'11 techno',\n",
        " u'11 who',\n",
        " u'11 year',\n",
        " u'110',\n",
        " u'110 million',\n",
        " u'110 minutes',\n",
        " u'112',\n",
        " u'112 minutes',\n",
        " u'1138',\n",
        " u'114',\n",
        " u'114 minute',\n",
        " u'118',\n",
        " u'118 minutes',\n",
        " u'11th',\n",
        " u'11th hour',\n",
        " u'12',\n",
        " u'12 age',\n",
        " u'12 and',\n",
        " u'12 angry',\n",
        " u'12 bond',\n",
        " u'12 endings',\n",
        " u'12 score',\n",
        " u'12 step',\n",
        " u'12 year',\n",
        " u'124',\n",
        " u'124 minute',\n",
        " u'124 minutes',\n",
        " u'125',\n",
        " u'125 million',\n",
        " u'125 minutes',\n",
        " u'128',\n",
        " u'128 minutes',\n",
        " u'13',\n",
        " u'13 going',\n",
        " u'13 in',\n",
        " u'13 into',\n",
        " u'13 movie',\n",
        " u'13 names',\n",
        " u'13 one',\n",
        " u'13 rating',\n",
        " u'13 ron',\n",
        " u'13 these',\n",
        " u'13 with',\n",
        " u'13 years',\n",
        " u'130',\n",
        " u'130 minute',\n",
        " u'132',\n",
        " u'132 minutes',\n",
        " u'133',\n",
        " u'133 minute',\n",
        " u'134',\n",
        " u'134 minutes',\n",
        " u'136',\n",
        " u'136 minutes',\n",
        " u'137',\n",
        " u'137 minutes',\n",
        " u'13th',\n",
        " u'13th and',\n",
        " u'13th part',\n",
        " u'13th to',\n",
        " u'13th warrior',\n",
        " u'13th was',\n",
        " u'14',\n",
        " u'14 year',\n",
        " u'14 years',\n",
        " u'141',\n",
        " u'141 minute',\n",
        " u'141 minutes',\n",
        " u'145',\n",
        " u'145 minutes',\n",
        " u'145 subplots',\n",
        " u'15',\n",
        " u'15 20',\n",
        " u'15 minutes',\n",
        " u'15 part',\n",
        " u'15 year',\n",
        " u'15 years',\n",
        " u'153',\n",
        " u'153 minutes',\n",
        " u'15th',\n",
        " u'15th century',\n",
        " u'16',\n",
        " u'16 months',\n",
        " u'16 was',\n",
        " u'16 years',\n",
        " u'160',\n",
        " u'160 minute',\n",
        " u'160 minutes',\n",
        " u'161',\n",
        " u'161 minutes',\n",
        " u'1660s',\n",
        " u'1660s tale',\n",
        " u'16mm',\n",
        " u'16mm film',\n",
        " u'16th',\n",
        " u'16th bond',\n",
        " u'17',\n",
        " u'17 bonds',\n",
        " u'17 from',\n",
        " u'17 million',\n",
        " u'17 rating',\n",
        " u'17 years',\n",
        " u'17th',\n",
        " u'17th century',\n",
        " u'18',\n",
        " u'18 years',\n",
        " u'180',\n",
        " u'180 degree',\n",
        " u'180 degrees',\n",
        " u'180 minute',\n",
        " u'185',\n",
        " u'185 minutes',\n",
        " u'1850',\n",
        " u'1850 as',\n",
        " u'187',\n",
        " u'187 minutes',\n",
        " u'1873',\n",
        " u'1873 novel',\n",
        " u'1879',\n",
        " u'1880s',\n",
        " u'1880s stage',\n",
        " u'1898',\n",
        " u'1898 alien',\n",
        " u'18th',\n",
        " u'18th century',\n",
        " u'19',\n",
        " u'19 1996',\n",
        " u'19 sees',\n",
        " u'19 year',\n",
        " u'1900s',\n",
        " u'1900s that',\n",
        " u'1910',\n",
        " u'1910 novel',\n",
        " u'1911',\n",
        " u'1911 children',\n",
        " u'1914',\n",
        " u'1914 polar',\n",
        " u'1917',\n",
        " u'1917 is',\n",
        " u'1920',\n",
        " u'1920 that',\n",
        " u'1920s',\n",
        " u'1920s and',\n",
        " u'1921',\n",
        " u'1921 1989',\n",
        " u'1925',\n",
        " u'1925 noel',\n",
        " u'1926',\n",
        " u'1926 evocation',\n",
        " u'1927',\n",
        " u'1927 the',\n",
        " u'1930',\n",
        " u'1930 but',\n",
        " u'1930 stylishness',\n",
        " u'1930s',\n",
        " u'1930s and',\n",
        " u'1930s hollywood',\n",
        " u'1930s horror',\n",
        " u'1930s not',\n",
        " u'1931',\n",
        " u'1931 by',\n",
        " u'1932',\n",
        " u'1932 hitchcock',\n",
        " u'1933',\n",
        " u'1933 book',\n",
        " u'1933 classic',\n",
        " u'1933 is',\n",
        " u'1933 manhattan',\n",
        " u'1933 original',\n",
        " u'1934',\n",
        " u'1934 hot',\n",
        " u'1934 inspired',\n",
        " u'1935',\n",
        " u'1935 musical',\n",
        " u'1936',\n",
        " u'1936 film',\n",
        " u'1937',\n",
        " u'1937 it',\n",
        " u'1938',\n",
        " u'1938 howard',\n",
        " u'1938 screwball',\n",
        " u'1939',\n",
        " u'1939 but',\n",
        " u'1939 comedy',\n",
        " u'1939 drama',\n",
        " u'1939 film',\n",
        " u'1939 original',\n",
        " u'1939 shirley',\n",
        " u'1940',\n",
        " u'1940 film',\n",
        " u'1940 pinocchio',\n",
        " u'1940 satire',\n",
        " u'1940s',\n",
        " u'1940s and',\n",
        " u'1940s filled',\n",
        " u'1940s film',\n",
        " u'1940s new',\n",
        " u'1941',\n",
        " u'1941 before',\n",
        " u'1941 comedy',\n",
        " u'1941 redeemed',\n",
        " u'1942',\n",
        " u'1942 about',\n",
        " u'1942 screwball',\n",
        " u'1943',\n",
        " u'1943 during',\n",
        " u'1946',\n",
        " u'1946 and',\n",
        " u'1946 detective',\n",
        " u'1948',\n",
        " u'1948 study',\n",
        " u'1948 to',\n",
        " u'1948 with',\n",
        " u'1950',\n",
        " u'1950 disney',\n",
        " u'1950 effort',\n",
        " u'1950 gem',\n",
        " u'1950 was',\n",
        " u'1950s',\n",
        " u'1950s america',\n",
        " u'1950s marriage',\n",
        " u'1950s sleaze',\n",
        " u'1950s tv',\n",
        " u'1950s universal',\n",
        " u'1950s william',\n",
        " u'1951',\n",
        " u'1951 film',\n",
        " u'1951 the',\n",
        " u'1952',\n",
        " u'1952 but',\n",
        " u'1952 children',\n",
        " u'1952 oscar',\n",
        " u'1952 story',\n",
        " u'1953',\n",
        " u'1953 but',\n",
        " u'1953 from',\n",
        " u'1953 version',\n",
        " u'1954',\n",
        " u'1954 is',\n",
        " u'1955',\n",
        " u'1955 and',\n",
        " u'1955 exercise',\n",
        " u'1956',\n",
        " u'1956 cannes',\n",
        " u'1956 musical',\n",
        " u'1956 production',\n",
        " u'1956 science',\n",
        " u'1957',\n",
        " u'1957 essay',\n",
        " u'1957 fellini',\n",
        " u'1957 is',\n",
        " u'1958',\n",
        " u'1958 horror',\n",
        " u'1958 plymouth',\n",
        " u'1959',\n",
        " u'1959 comedy',\n",
        " u'1959 is',\n",
        " u'1960',\n",
        " u'1960 masterpiece',\n",
        " u'1960 picture',\n",
        " u'1960 version',\n",
        " u'1960s',\n",
        " u'1960s catches',\n",
        " u'1960s cinematic',\n",
        " u'1960s films',\n",
        " u'1960s the',\n",
        " u'1960s visceral',\n",
        " u'1960s western',\n",
        " u'1961',\n",
        " u'1961 adaptation',\n",
        " u'1961 backyard',\n",
        " u'1961 children',\n",
        " u'1961 chiller',\n",
        " u'1961 cleo',\n",
        " u'1961 film',\n",
        " u'1961 hayley',\n",
        " u'1961 release',\n",
        " u'1961 richard',\n",
        " u'1961 that',\n",
        " u'1961 translation',\n",
        " u'1961 when',\n",
        " u'1962',\n",
        " u'1962 thriller',\n",
        " u'1963',\n",
        " u'1963 and',\n",
        " u'1963 attempt',\n",
        " u'1963 classic',\n",
        " u'1963 jerry',\n",
        " u'1963 the',\n",
        " u'1964',\n",
        " u'1964 entry',\n",
        " u'1964 hanks',\n",
        " u'1964 has',\n",
        " u'1964 is',\n",
        " u'1964 the',\n",
        " u'1965',\n",
        " u'1965 adaptation',\n",
        " u'1965 well',\n",
        " u'1966',\n",
        " u'1966 film',\n",
        " u'1966 spy',\n",
        " u'1966 western',\n",
        " u'1967',\n",
        " u'1967 film',\n",
        " u'1967 this',\n",
        " u'1968',\n",
        " u'1968 beatles',\n",
        " u'1968 mating',\n",
        " u'1968 novel',\n",
        " u'1968 original',\n",
        " u'1968 that',\n",
        " u'1968 the',\n",
        " u'1968 with',\n",
        " u'1969',\n",
        " u'1969 england',\n",
        " u'1970',\n",
        " u'1970 animated',\n",
        " u'1970 watermelon',\n",
        " u'1970s',\n",
        " u'1970s but',\n",
        " u'1970s issue',\n",
        " u'1970s it',\n",
        " u'1970s kitsch',\n",
        " u'1970s wave',\n",
        " u'1970s with',\n",
        " u'1971',\n",
        " u'1971 antiwestern',\n",
        " u'1971 hit',\n",
        " u'1971 thriller',\n",
        " u'1972',\n",
        " u'1972 film',\n",
        " u'1972 in',\n",
        " u'1973',\n",
        " u'1973 horror',\n",
        " u'1974',\n",
        " u'1974 and',\n",
        " u'1974 blood',\n",
        " u'1974 grisly',\n",
        " u'1974 original',\n",
        " u'1975',\n",
        " u'1975 and',\n",
        " u'1975 but',\n",
        " u'1975 exploitation',\n",
        " u'1975 feature',\n",
        " u'1975 film',\n",
        " u'1975 remains',\n",
        " u'1976',\n",
        " u'1976 is',\n",
        " u'1976 style',\n",
        " u'1976 thriller',\n",
        " u'1977',\n",
        " u'1977 and',\n",
        " u'1977 hit',\n",
        " u'1977 premiere',\n",
        " u'1979',\n",
        " u'1979 and',\n",
        " u'1979 film',\n",
        " u'1979 kramer',\n",
        " u'1979 movie',\n",
        " u'1979 original',\n",
        " u'1980',\n",
        " u'1980 fantasy',\n",
        " u'1980 feature',\n",
        " u'1980 original',\n",
        " u'1980 sequel',\n",
        " u'1980s',\n",
        " u'1980s as',\n",
        " u'1980s series',\n",
        " u'1981',\n",
        " u'1981 and',\n",
        " u'1981 noir',\n",
        " u'1982',\n",
        " u'1982 and',\n",
        " u'1982 career',\n",
        " u'1982 sex',\n",
        " u'1982 this',\n",
        " u'1983',\n",
        " u'1983 film',\n",
        " u'1984',\n",
        " u'1984 film',\n",
        " u'1984 stranger',\n",
        " u'1985',\n",
        " u'1985 film',\n",
        " u'1985 horror',\n",
        " u'1985 mystery',\n",
        " u'1985 tale',\n",
        " u'1986',\n",
        " u'1986 hollywood',\n",
        " u'1986 horror',\n",
        " u'1987',\n",
        " u'1987 and',\n",
        " u'1987 fairy',\n",
        " u'1987 thriller',\n",
        " u'1988',\n",
        " u'1988 john',\n",
        " u'1988 running',\n",
        " u'1989',\n",
        " u'1989 is',\n",
        " u'1989 on',\n",
        " u'1989 paradiso',\n",
        " u'1989 that',\n",
        " u'1990',\n",
        " u'1990 the',\n",
        " u'1990s',\n",
        " u'1990s moviemaking',\n",
        " u'1990s spin',\n",
        " u'1991',\n",
        " u'1991 desert',\n",
        " u'1991 gulf',\n",
        " u'1991 release',\n",
        " u'1992',\n",
        " u'1992 and',\n",
        " u'1992 feature',\n",
        " u'1992 original',\n",
        " u'1992 phenomenon',\n",
        " u'1992 the',\n",
        " u'1993',\n",
        " u'1993 groundhog',\n",
        " u'1993 it',\n",
        " u'1993 movie',\n",
        " u'1993 offers',\n",
        " u'1993 release',\n",
        " u'1993 spin',\n",
        " u'1993 twenty',\n",
        " u'1994',\n",
        " u'1994 is',\n",
        " u'1994 spellbinder',\n",
        " u'1994 the',\n",
        " u'1995',\n",
        " u'1995 feature',\n",
        " u'1995 it',\n",
        " u'1995 major',\n",
        " u'1995 mighty',\n",
        " u'1995 oscar',\n",
        " u'1995 that',\n",
        " u'1995 thriller',\n",
        " u'1995 toronto',\n",
        " u'1996',\n",
        " u'1996 best',\n",
        " u'1996 english',\n",
        " u'1996 film',\n",
        " u'1996 first',\n",
        " u'1996 in',\n",
        " u'1996 release',\n",
        " u'1996 sleeper',\n",
        " u'1997',\n",
        " u'1997 comedy',\n",
        " u'1997 family',\n",
        " u'1997 feature',\n",
        " u'1997 more',\n",
        " u'1997 the',\n",
        " u'1997 thriller',\n",
        " u'1998',\n",
        " u'1998 action',\n",
        " u'1998 displays',\n",
        " u'1998 feature',\n",
        " u'1998 movie',\n",
        " u'1998 romantic',\n",
        " u'1998 shocker',\n",
        " u'1998 sundance',\n",
        " u'1998 with',\n",
        " u'1999',\n",
        " u'1999 and',\n",
        " u'1999 high',\n",
        " u'1999 it',\n",
        " u'1999 satirical',\n",
        " u'1999 worst',\n",
        " u'19th',\n",
        " u'19th century',\n",
        " u'20',\n",
        " u'20 000',\n",
        " u'20 head',\n",
        " u'20 million',\n",
        " u'20 minute',\n",
        " u'20 minutes',\n",
        " u'20 or',\n",
        " u'20 years',\n",
        " u'2000',\n",
        " u'2000 isn',\n",
        " u'20000',\n",
        " u'20000 leagues',\n",
        " u'2001',\n",
        " u'2001 arizona',\n",
        " u'2001 as',\n",
        " u'2001 compares',\n",
        " u'2001 fans',\n",
        " u'2001 is',\n",
        " u'2001 it',\n",
        " u'2001 its',\n",
        " u'2001 lingers',\n",
        " u'2001 space',\n",
        " u'2001 the',\n",
        " u'2004',\n",
        " u'2004 as',\n",
        " u'2004 punisher',\n",
        " u'2006',\n",
        " u'2006 horror',\n",
        " u'2007',\n",
        " u'2007 but',\n",
        " u'2008',\n",
        " u'2008 and',\n",
        " u'2008 then',\n",
        " u'2009',\n",
        " u'2009 is',\n",
        " u'2010',\n",
        " u'2010 for',\n",
        " u'2010 is',\n",
        " u'2019',\n",
        " u'2019 in',\n",
        " u'2019 or',\n",
        " u'202',\n",
        " u'202 minutes',\n",
        " u'2033',\n",
        " u'207',\n",
        " u'207 minute',\n",
        " u'208',\n",
        " u'208 minutes',\n",
        " u'20s',\n",
        " u'20s for',\n",
        " u'20s made',\n",
        " u'20s period',\n",
        " u'20s when',\n",
        " u'20th',\n",
        " u'20th century',\n",
        " u'21',\n",
        " u'21 minute',\n",
        " u'21st',\n",
        " u'21st century',\n",
        " u'22',\n",
        " u'22 carnal',\n",
        " u'231',\n",
        " u'231 ois',\n",
        " u'24',\n",
        " u'24 carrot',\n",
        " u'24 hours',\n",
        " u'24 years',\n",
        " u'240',\n",
        " u'240 mph',\n",
        " u'25',\n",
        " u'25 belly',\n",
        " u'25 foot',\n",
        " u'25 year',\n",
        " u'25 years',\n",
        " u'250',\n",
        " u'250 with',\n",
        " u'25th',\n",
        " u'25th full',\n",
        " u'26',\n",
        " u'26 is',\n",
        " u'26 soderbergh',\n",
        " u'26 year',\n",
        " u'26 years',\n",
        " u'27',\n",
        " u'27 minutes',\n",
        " u'27 writer',\n",
        " u'28',\n",
        " u'28 days',\n",
        " u'28 year',\n",
        " u'29',\n",
        " u'29 year',\n",
        " u'2d',\n",
        " u'2d but',\n",
        " u'30',\n",
        " u'30 films',\n",
        " u'30 has',\n",
        " u'30 in',\n",
        " u'30 intolerably',\n",
        " u'30 million',\n",
        " u'30 minute',\n",
        " u'30 minutes',\n",
        " u'30 second',\n",
        " u'30 year',\n",
        " u'30 years',\n",
        " u'300',\n",
        " u'300 screens',\n",
        " u'3000',\n",
        " u'3000 the',\n",
        " u'30s',\n",
        " u'30s and',\n",
        " u'30s balanced',\n",
        " u'30s screwball',\n",
        " u'30s style',\n",
        " u'31',\n",
        " u'31 was',\n",
        " u'312',\n",
        " u'312 minutes',\n",
        " u'33',\n",
        " u'33 year',\n",
        " u'33rd',\n",
        " u'33rd animated',\n",
        " u'34',\n",
        " u'34 minutes',\n",
        " u'34 on',\n",
        " u'34th',\n",
        " u'34th street',\n",
        " u'35',\n",
        " u'35 with',\n",
        " u'35mm',\n",
        " u'35mm films',\n",
        " u'36',\n",
        " u'36 years',\n",
        " u'37',\n",
        " u'37 years',\n",
        " u'3d',\n",
        " u'3d shows',\n",
        " u'3d the',\n",
        " u'3d which',\n",
        " u'40',\n",
        " u'40 foot',\n",
        " u'40 million',\n",
        " u'40 minute',\n",
        " u'40 minutes',\n",
        " u'40 odd',\n",
        " u'40 pounds',\n",
        " u'40 year',\n",
        " u'40 years',\n",
        " u'400',\n",
        " u'400 blows',\n",
        " u'400 member',\n",
        " u'405',\n",
        " u'405 freeway',\n",
        " u'40s',\n",
        " u'40s contradicted',\n",
        " u'40s musical',\n",
        " u'41',\n",
        " u'41 year',\n",
        " u'42',\n",
        " u'42 minutes',\n",
        " u'42 up',\n",
        " u'42nd',\n",
        " u'42nd street',\n",
        " u'45',\n",
        " u'45 million',\n",
        " u'45 minutes',\n",
        " u'467',\n",
        " u'467 imitators',\n",
        " u'48',\n",
        " u'48 hours',\n",
        " u'50',\n",
        " u'50 losses',\n",
        " u'50 million',\n",
        " u'50 times',\n",
        " u'50 years',\n",
        " u'500',\n",
        " u'500 mile',\n",
        " u'50s',\n",
        " u'50s and',\n",
        " u'50s art',\n",
        " u'50s but',\n",
        " u'50s cartoon',\n",
        " u'50s death',\n",
        " u'50s directors',\n",
        " u'50s feeling',\n",
        " u'50s film',\n",
        " u'50s horror',\n",
        " u'50s jungle',\n",
        " u'50s melodrama',\n",
        " u'50s movies',\n",
        " u'50s nostalgia',\n",
        " u'50s sci',\n",
        " u'50s tv',\n",
        " u'51',\n",
        " u'51 minutes',\n",
        " u'54',\n",
        " u'54 is',\n",
        " u'55',\n",
        " u'55 he',\n",
        " u'56',\n",
        " u'56 year',\n",
        " u'60',\n",
        " u'60 million',\n",
        " u'60 minutes',\n",
        " u'60 piece',\n",
        " u'60s',\n",
        " u'60s and',\n",
        " u'60s brit',\n",
        " u'60s bummer',\n",
        " u'60s comedies',\n",
        " u'60s disney',\n",
        " u'60s easy',\n",
        " u'60s efforts',\n",
        " u'60s hoodlums',\n",
        " u'60s overseas',\n",
        " u'60s soul',\n",
        " u'60s tv',\n",
        " u'63',\n",
        " u'63 minutes',\n",
        " u'63 years',\n",
        " u'64257',\n",
        " u'64257 lm',\n",
        " u'65',\n",
        " u'65 that',\n",
        " u'666',\n",
        " u'666 book',\n",
        " u'69',\n",
        " u'69 evolves',\n",
        " u'69 minutes',\n",
        " u'70',\n",
        " u'70 and',\n",
        " u'70 mil',\n",
        " u'70 minutes',\n",
        " u'700',\n",
        " u'700 years',\n",
        " u'70s',\n",
        " u'70s amazing',\n",
        " u'70s american',\n",
        " u'70s and',\n",
        " u'70s classicism',\n",
        " u'70s exploitation',\n",
        " u'70s references',\n",
        " u'70s soul',\n",
        " u'70s stab',\n",
        " u'70s this',\n",
        " u'70s will',\n",
        " u'72',\n",
        " u'72 olympics',\n",
        " u'73',\n",
        " u'74',\n",
        " u'74 minutes',\n",
        " u'747s',\n",
        " u'747s handy',\n",
        " u'75',\n",
        " u'75 minute',\n",
        " u'75 minutes',\n",
        " u'75 the',\n",
        " u'75 years',\n",
        " u'75th',\n",
        " u'75th anniversary',\n",
        " u'76',\n",
        " u'76 years',\n",
        " u'78',\n",
        " u'78 year',\n",
        " u'79',\n",
        " u'79 year',\n",
        " u'80',\n",
        " u'80 days',\n",
        " u'80 million',\n",
        " u'80 minute',\n",
        " u'80 minutes',\n",
        " u'80 unbroken',\n",
        " u'80 year',\n",
        " u'80s',\n",
        " u'80s as',\n",
        " u'80s bond',\n",
        " u'80s dreck',\n",
        " u'80s is',\n",
        " u'80s most',\n",
        " u'80s tempered',\n",
        " u'80s this',\n",
        " u'80s with',\n",
        " u'80s you',\n",
        " u'80s youngsters',\n",
        " u'81',\n",
        " u'81 minutes',\n",
        " u'82',\n",
        " u'82 the',\n",
        " u'8212',\n",
        " u'8212 but',\n",
        " u'83',\n",
        " u'83 minutes',\n",
        " u'83 years',\n",
        " u'84',\n",
        " u'84 minutes',\n",
        " u'85',\n",
        " u'85 minute',\n",
        " u'85 minutes',\n",
        " u'87',\n",
        " u'87 minutes',\n",
        " u'88',\n",
        " u'88 minutes',\n",
        " u'90',\n",
        " u'90 minute',\n",
        " u'90 minutes',\n",
        " u'90 or',\n",
        " u'90 seconds',\n",
        " u'90 twist',\n",
        " u'90m',\n",
        " u'90m revisionist',\n",
        " u'90s',\n",
        " u'90s but',\n",
        " u'90s casino',\n",
        " u'90s horror',\n",
        " u'90s ideal',\n",
        " u'90s in',\n",
        " u'90s is',\n",
        " u'90s nor',\n",
        " u'90s purposelessness',\n",
        " u'90s remake',\n",
        " u'90s sensibility',\n",
        " u'90s style',\n",
        " u'90s take',\n",
        " u'91',\n",
        " u'91 minutes',\n",
        " u'92',\n",
        " u'92 minute',\n",
        " u'92 minutes',\n",
        " u'93',\n",
        " u'93 minutes',\n",
        " u'95',\n",
        " u'95 and',\n",
        " u'95 minutes',\n",
        " u'98',\n",
        " u'98 minutes',\n",
        " u'98 startle',\n",
        " u'99',\n",
        " u'99 95',\n",
        " u'99 minutes',\n",
        " u'99 on',\n",
        " u'_and_',\n",
        " u'_and_ the',\n",
        " u'aaron',\n",
        " u'aaron and',\n",
        " u'aaron copland',\n",
        " u'aaron life',\n",
        " u'aaron sorkin',\n",
        " u'abandon',\n",
        " u'abandon and',\n",
        " u'abandon when',\n",
        " u'abandoned',\n",
        " u'abandoned conventional',\n",
        " u'abandonment',\n",
        " u'abandonment and',\n",
        " u'abandons',\n",
        " u'abbott',\n",
        " u'abbott and',\n",
        " u'abbreviated',\n",
        " u'abbreviated others',\n",
        " u'abbreviated style',\n",
        " u'abc',\n",
        " u'abc 72',\n",
        " u'abc full',\n",
        " u'abc small',\n",
        " u'abdominal',\n",
        " u'abdominal comedy',\n",
        " u'abduct',\n",
        " u'abduct the',\n",
        " u'abe',\n",
        " u'abe lincoln',\n",
        " u'abe rather',\n",
        " u'abel',\n",
        " u'abel ferrara',\n",
        " u'abel gance',\n",
        " u'abets',\n",
        " u'abets cultural',\n",
        " u'abets it',\n",
        " u'abiding',\n",
        " u'abiding fascinations',\n",
        " u'abilities',\n",
        " u'abilities the',\n",
        " u'abilities to',\n",
        " u'ability',\n",
        " u'ability and',\n",
        " u'ability but',\n",
        " u'ability for',\n",
        " u'ability of',\n",
        " u'ability on',\n",
        " u'ability outstrip',\n",
        " u'ability to',\n",
        " u'abject',\n",
        " u'abject desperation',\n",
        " u'ablazin',\n",
        " u'ablazin vamped',\n",
        " u'able',\n",
        " u'able actors',\n",
        " u'able both',\n",
        " u'able lane',\n",
        " u'able to',\n",
        " u'able writing',\n",
        " u'ably',\n",
        " u'ably directed',\n",
        " u'ably fitting',\n",
        " u'ably in',\n",
        " u'ably supported',\n",
        " u'aboard',\n",
        " u'aboard and',\n",
        " u'aboard are',\n",
        " u'aboard even',\n",
        " u'aboard in',\n",
        " u'aboard this',\n",
        " u'abominable',\n",
        " u'abominable abdominal',\n",
        " u'abomination',\n",
        " u'aborted',\n",
        " u'aborted encounters',\n",
        " u'aborted long',\n",
        " u'abortion',\n",
        " u'abortion and',\n",
        " u'abound',\n",
        " u'abound as',\n",
        " u'abound but',\n",
        " u'abound creating',\n",
        " u'abound in',\n",
        " u'abounds',\n",
        " u'abounds in',\n",
        " u'abounds with',\n",
        " u'about',\n",
        " u'about 10',\n",
        " u'about 100',\n",
        " u'about 12',\n",
        " u'about 15',\n",
        " u'about 19th',\n",
        " u'about 20',\n",
        " u'about 2001',\n",
        " u'about 240',\n",
        " u'about 250',\n",
        " u'about 30',\n",
        " u'about 40',\n",
        " u'about 70',\n",
        " u'about 90',\n",
        " u'about 90s',\n",
        " u'about 99',\n",
        " u'about abandonment',\n",
        " u'about accomplished',\n",
        " u'about actors',\n",
        " u'about afterward',\n",
        " u'about age',\n",
        " u'about aids',\n",
        " u'about airheads',\n",
        " u'about alientaion',\n",
        " u'about all',\n",
        " u'about america',\n",
        " u'about american',\n",
        " u'about americans',\n",
        " u'about amistad',\n",
        " u'about an',\n",
        " u'about and',\n",
        " u'about anne',\n",
        " u'about another',\n",
        " u'about any',\n",
        " u'about anyone',\n",
        " ...]"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create a vector where each row is bag-of-words for a singe quote\n",
      "X = vectorizer.transform(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 6446)\t2\n",
        "  (0, 7541)\t1\n",
        "  (0, 9611)\t1\n",
        "  (0, 16454)\t1\n",
        "  (0, 16644)\t1\n",
        "  (0, 23678)\t1\n",
        "  (0, 23934)\t1\n",
        "  (0, 27068)\t1\n",
        "  (0, 30919)\t1\n",
        "  (0, 30924)\t1\n",
        "  (0, 32582)\t1\n",
        "  (0, 32660)\t1\n",
        "  (0, 36918)\t1\n",
        "  (0, 36919)\t1\n",
        "  (0, 43885)\t1\n",
        "  (0, 43886)\t1\n",
        "  (0, 46504)\t1\n",
        "  (0, 46509)\t1\n",
        "  (0, 68218)\t1\n",
        "  (0, 68456)\t1\n",
        "  (0, 70236)\t1\n",
        "  (0, 70242)\t1\n",
        "  (0, 74183)\t1\n",
        "  (0, 74887)\t1\n",
        "  (0, 75443)\t1\n",
        "  :\t:\n",
        "  (14071, 61942)\t1\n",
        "  (14071, 70595)\t1\n",
        "  (14071, 70597)\t1\n",
        "  (14071, 71159)\t1\n",
        "  (14071, 71185)\t1\n",
        "  (14071, 74183)\t1\n",
        "  (14071, 74474)\t1\n",
        "  (14071, 78103)\t1\n",
        "  (14071, 78133)\t1\n",
        "  (14071, 81090)\t1\n",
        "  (14071, 81108)\t1\n",
        "  (14071, 96820)\t1\n",
        "  (14071, 98137)\t1\n",
        "  (14071, 110536)\t1\n",
        "  (14071, 110549)\t1\n",
        "  (14071, 131226)\t1\n",
        "  (14071, 131227)\t1\n",
        "  (14071, 137665)\t2\n",
        "  (14071, 139792)\t1\n",
        "  (14071, 141490)\t1\n",
        "  (14071, 145418)\t1\n",
        "  (14071, 145554)\t1\n",
        "  (14071, 145919)\t1\n",
        "  (14071, 146659)\t1\n",
        "  (14071, 152280)\t1\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The fitting and the transform could be done in 1 single step\n",
      "# using fit_transform!!.. more efficient\n",
      "# X : sparse matrix, [n_samples, n_features]\n",
      "\n",
      "# documentation: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names\n",
      "\n",
      "X = vectorizer.fit_transform(critics.quote)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 126031)\t1\n",
        "  (0, 70236)\t1\n",
        "  (0, 68218)\t1\n",
        "  (0, 30919)\t1\n",
        "  (0, 36918)\t1\n",
        "  (0, 6446)\t2\n",
        "  (0, 46504)\t1\n",
        "  (0, 136476)\t1\n",
        "  (0, 162696)\t1\n",
        "  (0, 32582)\t1\n",
        "  (0, 155773)\t1\n",
        "  (0, 74183)\t1\n",
        "  (0, 100464)\t1\n",
        "  (0, 108976)\t1\n",
        "  (0, 129252)\t1\n",
        "  (0, 124784)\t1\n",
        "  (0, 120073)\t1\n",
        "  (0, 130059)\t1\n",
        "  (0, 16454)\t1\n",
        "  (0, 43885)\t1\n",
        "  (0, 23678)\t1\n",
        "  (0, 75443)\t1\n",
        "  (0, 27068)\t1\n",
        "  (0, 126219)\t1\n",
        "  (0, 70242)\t1\n",
        "  :\t:\n",
        "  (14071, 145418)\t1\n",
        "  (14071, 110536)\t1\n",
        "  (14071, 39514)\t1\n",
        "  (14071, 44081)\t1\n",
        "  (14071, 146659)\t1\n",
        "  (14071, 141490)\t1\n",
        "  (14071, 74474)\t1\n",
        "  (14071, 7715)\t1\n",
        "  (14071, 37185)\t1\n",
        "  (14071, 39569)\t1\n",
        "  (14071, 61942)\t1\n",
        "  (14071, 98137)\t1\n",
        "  (14071, 1730)\t1\n",
        "  (14071, 59727)\t1\n",
        "  (14071, 70595)\t1\n",
        "  (14071, 131226)\t1\n",
        "  (14071, 70597)\t1\n",
        "  (14071, 44125)\t1\n",
        "  (14071, 59730)\t1\n",
        "  (14071, 145554)\t1\n",
        "  (14071, 131227)\t1\n",
        "  (14071, 1734)\t1\n",
        "  (14071, 110549)\t1\n",
        "  (14071, 37204)\t1\n",
        "  (14071, 71185)\t1\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create an array where each element encodes whether the array\n",
      "# is Fresh or Rotten\n",
      "\n",
      "critics.fresh.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "fresh     8613\n",
        "rotten    5436\n",
        "none        23\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = (critics.fresh == 'fresh').values.astype(np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "array([1, 1, 1, ..., 1, 1, 1])"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(Y), len(Y[Y == 1]), len(Y[Y == 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14072 8613 5459\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use SKLearn's train_test_split\n",
      "from sklearn.cross_validation import train_test_split\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xtrain, xtest, ytrain, ytest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "(<10554x163505 sparse matrix of type '<type 'numpy.int64'>'\n",
        " \twith 375727 stored elements in Compressed Sparse Row format>,\n",
        " <3518x163505 sparse matrix of type '<type 'numpy.int64'>'\n",
        " \twith 127166 stored elements in Compressed Sparse Row format>,\n",
        " array([0, 0, 1, ..., 0, 1, 0]),\n",
        " array([0, 1, 0, ..., 1, 1, 1]))"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now with the data split into training and testing.. let's get \n",
      "# on with the classifiier.."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# vector of all quotes\n",
      "rotten_vectorizer = vectorizer.fit(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this helper function helps us better compare the accuracy\n",
      "# and predicability of our different model choices \n",
      "\n",
      "def accuracy_report(_clf):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
      "\n",
      "# this helper function helps us see how a certain review performed\n",
      "# according to the model \n",
      "\n",
      "def AnalyzeReview(testquote, _clf):\n",
      "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
      "    testquote = rotten_vectorizer.transform([testquote])\n",
      "\n",
      "    if (_clf.predict(testquote)[0] == 1):\n",
      "        print \"... a fresh review.\"\n",
      "    else:\n",
      "        print \"... a rotten review.\"\n",
      "    return(clf.predict(testquote)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's run the naive bayes classification with MultinomialNB Link\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "print \"MultinomialNB:\"\n",
      "clf_mn = MultinomialNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf_mn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MultinomialNB:\n",
        "Accuracy: 77.66%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's run the naive bayes classification with BernoulliNB Link\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "print \"BernoulliNB:\"\n",
      "clf_b = BernoulliNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf_b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB:\n",
        "Accuracy: 66.06%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.87"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's run the naive bayes classification with Logistic Regression Link\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "print \"Logistic Regression:\"\n",
      "clf_lr = LogisticRegression().fit(xtrain, ytrain)\n",
      "accuracy_report(clf_lr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression:\n",
        "Accuracy: 77.09%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# looks like Logistic is on-par with Multinomial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's look at how the model reviews a single text review\n",
      "\n",
      "#commented out the helper function AnalyzeReview.. it wasn't working\n",
      "#AnalyzeReview(\"This movie was awesome\", clf_mn)\n",
      "testquote = \"This movie is awesome\"\n",
      "\n",
      "testquote_vec = rotten_vectorizer.transform([test_quote])\n",
      "clf_b.predict(test_quote_vec)[0]\n",
      "clf_b.predict_proba(test_quote_vec)[0]\n",
      "\n",
      "AnalyzeReview(testquote, clf_b)\n",
      "\n",
      "# print 'clf_b:'\n",
      "# AnalyzeReview(testquote, clf_b)\n",
      "# AnalyzeReview(testquote, clf_mn)\n",
      "# AnalyzeReview(testquote, clf_lr)\n",
      "# print \"Multinomial classifies this quote as\",clf_mn.predict(testquote)[0]\n",
      "# print \"Multinomial classifies this quote as\",clf_b.predict(testquote)[0]\n",
      "# print \"Multinomial classifies this quote as\",clf_lr.predict(testquote)[0]\n",
      "\n",
      "# 0 means it is rotten rview, 1 means it is a fresh review\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"This movie is awesome\" is judged by clasifier to be...\n",
        "... a fresh review.\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'function' object has no attribute 'predict'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-147-6d097c4f1ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclf_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_quote_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mAnalyzeReview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestquote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# print 'clf_b:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-96-539c69f98c0f>\u001b[0m in \u001b[0;36mAnalyzeReview\u001b[1;34m(testquote, _clf)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"... a rotten review.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestquote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save the prediction, probability, and take a look at the \n",
      "# mis-predicted / mis-classified errors\n",
      "\n",
      "# let's use the Bernoulli Model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# outputs of X, just the first column\n",
      "prob = clf_b.predict_proba(X)[:, 0]\n",
      "predict = clf_b.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y == 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 119,
       "text": [
        "array([False, False, False, ..., False, False, False], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# argsort returns the positions of the top n sorted values\n",
      "np.argsort((prob[Y==0]))[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 128,
       "text": [
        "array([2800, 1962, 3988, 2109, 1988])"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Top 5 Review classification errors\n",
      "bad_rotten = np.argsort(prob[Y == 0])[:5]\n",
      "bad_fresh = np.argsort(prob[Y == 1])[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visually take a look at the quotes that are mis-predicted,\n",
      "# separated by rotten and fresh quotes\n",
      "\n",
      "print \"Mis-predicted Rotten quotes\"\n",
      "print '---------------------------'\n",
      "for row in bad_rotten:\n",
      "    print critics[Y == 0].quote.irow(row)\n",
      "    print\n",
      "\n",
      "print \"Mis-predicted Fresh quotes\"\n",
      "print '--------------------------'\n",
      "for row in bad_fresh:\n",
      "    print critics[Y == 1].quote.irow(row)\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mis-predicted Rotten quotes\n",
        "---------------------------\n",
        "Where the Wild Things Are is audacious in its refusal to be reassuring, which makes it hard to love, but also hard to dismiss.\n",
        "\n",
        "Martin Scorsese makes pictures about the kinds of people you wouldn't want to know.\n",
        "\n",
        "A passable piece of summer hokum, but it underlines how difficult it has become to make an effective horror movie.\n",
        "\n",
        "It is sometimes funny in a puzzling kind of way, it is generally overwrought in an irritating kind of way, and once in a while it is inappropriately touching.\n",
        "\n",
        "It's a fun time at the movies.\n",
        "\n",
        "Mis-predicted Fresh quotes\n",
        "--------------------------\n",
        "The movie's basic joke holds that the overbearing, unselfconscious Americans will do anything and say anything (and usually as loudly as possible), while the timorous British are nearly too polite to breathe.\n",
        "\n",
        "The movie's own payoff is compelling enough, but the project has a weightless feel that limits involvement. Better you give it an hour-and-a-half on video someday, surrounded by wine and snacks.\n",
        "\n",
        "Dumb and Dumber, which features Carrey and Jeff Daniels as nitwits traveling cross-country, is a frayed string of gags posing as a movie. Carrey, though, does literal-minded doofdom with peerless enthusiasm."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Levinson must have felt he had to swing for the fences. He can be forgiven for choking up with all The Natural's fans looking on dubiously. In fairness, the official scorer must credit him with a single. And Redford with an RBI.\n",
        "\n",
        "More of a cinematic joke book than a real movie, Spy Hard hits you with gags faster than Henny Youngman on speed. Even when individual bits misfire, the unrelenting barrage of silliness can break down your resistance."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}