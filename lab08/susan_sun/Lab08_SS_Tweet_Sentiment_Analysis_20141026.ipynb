{
 "metadata": {
  "name": "",
  "signature": "sha256:194a91e955f0a8ee10dba2b38e3e0c664379f4a303731aa8afbc49899191dc97"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Class 08 - Bayes - Lab Tweet Sentiment Analysis\n",
      "\n",
      "# Create a twitter classifier with naive bayes and check the \n",
      "# sentiment for a keyword of your choice.  Train your classifier\n",
      "# with the \"tweet_training.csv\" file\n",
      "\n",
      "# Sentiment is described as \"polarity\" where\n",
      "\n",
      "# 0 = negative\n",
      "# 4 = positive\n",
      "\n",
      "# Goal: see if we can predict positive or negative sentiment on \n",
      "# Twitter based on analyzing the text on the tweets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data import\n",
      "tweets = pd.read_csv('https://raw.githubusercontent.com/vinharng/fall_2014_lessons/master/datasets/tweet_training.csv', delimiter=';', index_col='id')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1467933112</th>\n",
        "      <td> 0</td>\n",
        "      <td> the angel is going to miss the athlete this we...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2323395086</th>\n",
        "      <td> 0</td>\n",
        "      <td> It looks as though Shaq is getting traded to C...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1467968979</th>\n",
        "      <td> 0</td>\n",
        "      <td>    @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1990283756</th>\n",
        "      <td> 0</td>\n",
        "      <td> drinking a McDonalds coffee and not understand...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1988884918</th>\n",
        "      <td> 0</td>\n",
        "      <td> So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "            polarity                                              tweet\n",
        "id                                                                     \n",
        "1467933112         0  the angel is going to miss the athlete this we...\n",
        "2323395086         0  It looks as though Shaq is getting traded to C...\n",
        "1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
        "1990283756         0  drinking a McDonalds coffee and not understand...\n",
        "1988884918         0  So dissapointed Taylor Swift doesnt have a Twi..."
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the n_grams for 1 to 5\n",
      "\n",
      "# stop words \n",
      "# In computing, stop words are words which are filtered out before \n",
      "# or after processing of natural language data (text). There is n\n",
      "# ot one definite list of stop words which all tools use and such a \n",
      "# filter is not always used. Some tools specifically avoid removing \n",
      "# them to support phrase search.\n",
      "\n",
      "# For some search engines, these are some of the most common, short \n",
      "# function words, such as the, is, at, which, and on. \n",
      "\n",
      "# stop_words : string {\u2018english\u2019}, list, or None (default)\n",
      "# If \u2018english\u2019, a built-in stop word list for English is used.\n",
      "# If a list, that list is assumed to contain stop words, all of which \n",
      "# will be removed from the resulting tokens.\n",
      "# If None, no stop words will be used. max_df can be set to a value in \n",
      "# the range [0.7, 1.0) to automatically detect and filter stop words \n",
      "# based on intra corpus document frequency of terms."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build n_gram of 1 to 5, with stop_words = english\n",
      "vectorizer = CountVectorizer(ngram_range = (1,5), stop_words = 'english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 5), preprocessor=None, stop_words='english',\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call \"fit\" to build the vocabulary\n",
      "tweets_vectorizer = vectorizer.fit(tweets.tweet)\n",
      "tweets_vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 5), preprocessor=None, stop_words='english',\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#take a look at all the n_grams formed..\n",
      "tweets_vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[u'00',\n",
        " u'00 lol',\n",
        " u'00 lol ur',\n",
        " u'00 lol ur really',\n",
        " u'00 lol ur really pretty',\n",
        " u'00 m33',\n",
        " u'000',\n",
        " u'000 followers',\n",
        " u'000 followers wow',\n",
        " u'000 followers wow times',\n",
        " u'000 start',\n",
        " u'000gbp',\n",
        " u'000gbp breast',\n",
        " u'000gbp breast cancer',\n",
        " u'000gbp breast cancer great',\n",
        " u'000gbp breast cancer great night',\n",
        " u'00am',\n",
        " u'00am little',\n",
        " u'00am little bummed',\n",
        " u'00am little bummed gonna',\n",
        " u'00am little bummed gonna miss',\n",
        " u'06',\n",
        " u'06 17',\n",
        " u'06 38',\n",
        " u'06 38 london',\n",
        " u'06 38 london liverpool',\n",
        " u'06 38 london liverpool street',\n",
        " u'06h8t',\n",
        " u'08tv6',\n",
        " u'09',\n",
        " u'09 looking',\n",
        " u'09 looking pretty',\n",
        " u'09 looking pretty solid',\n",
        " u'09 looking pretty solid pick',\n",
        " u'0gb',\n",
        " u'0gb left',\n",
        " u'0gb left iphone',\n",
        " u'0gb left iphone want',\n",
        " u'0gb left iphone want new',\n",
        " u'10',\n",
        " u'10 cancer',\n",
        " u'10 cancer free',\n",
        " u'10 cancer free years',\n",
        " u'10 cancer free years yay',\n",
        " u'10 cards',\n",
        " u'10 cards hate',\n",
        " u'10 cards hate buying',\n",
        " u'10 cards hate buying left',\n",
        " u'10 day',\n",
        " u'10 day gonna',\n",
        " u'10 day gonna fly',\n",
        " u'10 day gonna fly miss',\n",
        " u'10 days',\n",
        " u'10 days tumaini',\n",
        " u'10 days tumaini international',\n",
        " u'10 days tumaini international loving',\n",
        " u'10 hehe',\n",
        " u'10 hehe yess',\n",
        " u'10 ve',\n",
        " u'10 ve happily',\n",
        " u'10 ve happily gone',\n",
        " u'10 ve happily gone boba',\n",
        " u'100',\n",
        " u'100 000',\n",
        " u'100 000 followers',\n",
        " u'100 000 followers wow',\n",
        " u'100 000 followers wow times',\n",
        " u'100 followers',\n",
        " u'100 followers exciting',\n",
        " u'100 having',\n",
        " u'100 having 30',\n",
        " u'100 having 30 000',\n",
        " u'100 having 30 000 start',\n",
        " u'100 people',\n",
        " u'100 votes',\n",
        " u'100 votes obama',\n",
        " u'100 votes obama rock',\n",
        " u'100 votes obama rock grass',\n",
        " u'100 xbox',\n",
        " u'100 xbox live',\n",
        " u'100 xbox live fun',\n",
        " u'101',\n",
        " u'101 dnt',\n",
        " u'101 dnt work',\n",
        " u'101 dnt work sydney',\n",
        " u'101 dnt work sydney just',\n",
        " u'101 fever',\n",
        " u'101 riddled',\n",
        " u'101 riddled cancer',\n",
        " u'101 riddled cancer commercials',\n",
        " u'101 riddled cancer commercials kinda',\n",
        " u'102',\n",
        " u'102 fever',\n",
        " u'102 fever night',\n",
        " u'103',\n",
        " u'103 pray',\n",
        " u'103 pray sweet',\n",
        " u'103 pray sweet girl',\n",
        " u'10k',\n",
        " u'10k xbox',\n",
        " u'10k xbox years',\n",
        " u'11',\n",
        " u'11 sadie',\n",
        " u'11 sadie daughter',\n",
        " u'11 sadie daughter angel',\n",
        " u'11 sadie daughter angel age',\n",
        " u'111',\n",
        " u'111 followers',\n",
        " u'111 followers thank',\n",
        " u'111 followers thank robots',\n",
        " u'11vcij',\n",
        " u'12',\n",
        " u'12 gym',\n",
        " u'12 gym class',\n",
        " u'12 gym class 10',\n",
        " u'12 gym class 10 day',\n",
        " u'12 hours',\n",
        " u'12 hours left',\n",
        " u'12 hours left download',\n",
        " u'12 pages',\n",
        " u'12 pages left',\n",
        " u'12 work',\n",
        " u'12 work 12',\n",
        " u'12 work 12 gym',\n",
        " u'12 work 12 gym class',\n",
        " u'1205308493',\n",
        " u'1205308493 html',\n",
        " u'1205308493 html damn',\n",
        " u'1205308493 html damn bike',\n",
        " u'1205308493 html damn bike want',\n",
        " u'123',\n",
        " u'123 days',\n",
        " u'123 days taylor',\n",
        " u'123 days taylor swift',\n",
        " u'123 days taylor swift concert',\n",
        " u'12th',\n",
        " u'13',\n",
        " u'13 30',\n",
        " u'13 30 iphone',\n",
        " u'13 30 iphone talk',\n",
        " u'13 30 iphone talk keeping',\n",
        " u'13 glad',\n",
        " u'13 glad twitter',\n",
        " u'13 glad twitter awesome',\n",
        " u'13 half',\n",
        " u'13 half looking',\n",
        " u'13 half looking good',\n",
        " u'130',\n",
        " u'130 pics',\n",
        " u'130 pics iphone',\n",
        " u'130 pics iphone flickit',\n",
        " u'130 pics iphone flickit app',\n",
        " u'14',\n",
        " u'14 amp',\n",
        " u'14 amp london',\n",
        " u'14 amp london names',\n",
        " u'14 amp london names charlotte',\n",
        " u'14 year',\n",
        " u'14 year old',\n",
        " u'14 year old looks',\n",
        " u'14 year old looks like',\n",
        " u'14 year wait',\n",
        " u'14 year wait finals',\n",
        " u'14 year wait finals sorry',\n",
        " u'15',\n",
        " u'15 hours',\n",
        " u'15 hours ago',\n",
        " u'15 hours ago golakers',\n",
        " u'15 oh',\n",
        " u'15 oh hard',\n",
        " u'15 oh hard drive',\n",
        " u'15 oh hard drive come',\n",
        " u'15 times',\n",
        " u'15 times hours',\n",
        " u'150',\n",
        " u'150 xbox',\n",
        " u'150 xbox lets',\n",
        " u'150 xbox lets really',\n",
        " u'150 xbox lets really costs',\n",
        " u'15th',\n",
        " u'15th july',\n",
        " u'15th july ll',\n",
        " u'15th july ll england',\n",
        " u'15th july ll england 19th',\n",
        " u'15th june',\n",
        " u'15th june xx',\n",
        " u'16',\n",
        " u'16 4th',\n",
        " u'16 4th quarter',\n",
        " u'16 4th quarter bout',\n",
        " u'16 4th quarter bout start',\n",
        " u'160',\n",
        " u'16bolq',\n",
        " u'16bolq ftsk',\n",
        " u'16bolq ftsk version',\n",
        " u'16bolq ftsk version taylor',\n",
        " u'16bolq ftsk version taylor swift',\n",
        " u'16gb',\n",
        " u'16gb 209',\n",
        " u'16gb 209 bloody',\n",
        " u'16gb 209 bloody hell',\n",
        " u'16gb ipod',\n",
        " u'16gb ipod touch',\n",
        " u'16gb ipod touch sony',\n",
        " u'16gb ipod touch sony hts',\n",
        " u'17',\n",
        " u'17nsud',\n",
        " u'17nwof',\n",
        " u'17th',\n",
        " u'17th 12',\n",
        " u'17th 12 hours',\n",
        " u'17th 12 hours left',\n",
        " u'17th 12 hours left download',\n",
        " u'1970s',\n",
        " u'1970s quot',\n",
        " u'1970s quot died',\n",
        " u'1970s quot died cancer',\n",
        " u'1970s quot died cancer aged',\n",
        " u'19th',\n",
        " u'19th crap',\n",
        " u'1a7zpw',\n",
        " u'1b',\n",
        " u'1b does',\n",
        " u'1b does allow',\n",
        " u'1b does allow response',\n",
        " u'1b does allow response facebook',\n",
        " u'1pm',\n",
        " u'1pm big',\n",
        " u'1pm big night',\n",
        " u'1st',\n",
        " u'1st birthday',\n",
        " u'1st birthday party',\n",
        " u'1st birthday party jerk',\n",
        " u'1st birthday party jerk headache',\n",
        " u'1st coffee',\n",
        " u'1st coffee day',\n",
        " u'1st coffee day happy',\n",
        " u'1st coffee day happy tuesday',\n",
        " u'1st day',\n",
        " u'1st day work',\n",
        " u'1st day work sunday',\n",
        " u'1st game',\n",
        " u'1st game downloaded',\n",
        " u'1st game downloaded psp',\n",
        " u'1st game downloaded psp didn',\n",
        " u'1st page',\n",
        " u'1st page 100',\n",
        " u'1st page 100 votes',\n",
        " u'1st page 100 votes obama',\n",
        " u'1st sydney',\n",
        " u'1st sydney ss',\n",
        " u'1st sydney ss sold',\n",
        " u'1st sydney ss sold driver',\n",
        " u'1st win',\n",
        " u'1st win wife',\n",
        " u'1st win wife smile',\n",
        " u'1vs100xboxlive',\n",
        " u'1vs100xboxlive just',\n",
        " u'1vs100xboxlive just got',\n",
        " u'1vs100xboxlive just got dropped',\n",
        " u'1vs100xboxlive just got dropped game',\n",
        " u'1xtti',\n",
        " u'20',\n",
        " u'20 believe',\n",
        " u'20 believe ve',\n",
        " u'20 believe ve tried',\n",
        " u'20 believe ve tried just',\n",
        " u'20 mcdonalds',\n",
        " u'20 mcdonalds breakfast',\n",
        " u'20 mcdonalds breakfast today',\n",
        " u'20 mins',\n",
        " u'20 mins home',\n",
        " u'20 mins home owe',\n",
        " u'20 mins home owe john',\n",
        " u'20 mins left',\n",
        " u'20 mins left just',\n",
        " u'20 mins left just case',\n",
        " u'20 pages',\n",
        " u'20 pages novel',\n",
        " u'200',\n",
        " u'200 crunches',\n",
        " u'200 crunches step',\n",
        " u'200 crunches step diddy',\n",
        " u'200 crunches step diddy lets',\n",
        " u'2009',\n",
        " u'2009 06',\n",
        " u'2009 06 17',\n",
        " u'2010',\n",
        " u'2010 home',\n",
        " u'2010 home city',\n",
        " u'2010 home city suck',\n",
        " u'2010 home city suck ah',\n",
        " u'2010 xboxe3',\n",
        " u'209',\n",
        " u'209 bloody',\n",
        " u'209 bloody hell',\n",
        " u'20th',\n",
        " u'20th google',\n",
        " u'20th google accidental',\n",
        " u'20th google accidental clicks',\n",
        " u'20th google accidental clicks spent',\n",
        " u'22',\n",
        " u'22 female',\n",
        " u'22 female california',\n",
        " u'228',\n",
        " u'228 people',\n",
        " u'228 people lost',\n",
        " u'228 people lost sea',\n",
        " u'228 people lost sea http',\n",
        " u'23',\n",
        " u'23 slides',\n",
        " u'23 slides crying',\n",
        " u'23 slides crying week',\n",
        " u'23 slides crying week hardest',\n",
        " u'23 vs',\n",
        " u'23 vs 24',\n",
        " u'231',\n",
        " u'231 sore',\n",
        " u'231 sore throat',\n",
        " u'231 sore throat headache',\n",
        " u'24',\n",
        " u'24 boring',\n",
        " u'24 boring madame',\n",
        " u'24 boring madame president',\n",
        " u'24 boring madame president crazy',\n",
        " u'24 hours',\n",
        " u'24 hours got',\n",
        " u'24 hours got 260',\n",
        " u'24 hours got 260 371',\n",
        " u'24 hours lame',\n",
        " u'24 hours straight',\n",
        " u'24 hours straight naps',\n",
        " u'24 hours straight naps gnite',\n",
        " u'24 pages',\n",
        " u'24 pages daddy',\n",
        " u'24 vegas',\n",
        " u'24 vegas remember',\n",
        " u'24 vegas remember having',\n",
        " u'24 vegas remember having breakfast',\n",
        " u'24hrs',\n",
        " u'24hrs anymore',\n",
        " u'25',\n",
        " u'25 1b',\n",
        " u'25 1b does',\n",
        " u'25 1b does allow',\n",
        " u'25 1b does allow response',\n",
        " u'25 pts',\n",
        " u'25 pts attitude',\n",
        " u'25 pts attitude tired',\n",
        " u'25th',\n",
        " u'260',\n",
        " u'260 371',\n",
        " u'260 371 followers',\n",
        " u'260 371 followers counting',\n",
        " u'260 371 followers counting girlfriend',\n",
        " u'28',\n",
        " u'28 days',\n",
        " u'28 days rain',\n",
        " u'28 days rain seattle',\n",
        " u'28 days rain seattle end',\n",
        " u'28 grams',\n",
        " u'28 grams fat',\n",
        " u'28 grams fat 41',\n",
        " u'28 grams fat 41 carbs',\n",
        " u'28th',\n",
        " u'28th follower',\n",
        " u'28th follower oprah',\n",
        " u'28th follower oprah sent',\n",
        " u'29823782',\n",
        " u'29823782 different',\n",
        " u'29823782 different things',\n",
        " u'29823782 different things kevin',\n",
        " u'29823782 different things kevin jonas',\n",
        " u'2day',\n",
        " u'2day fm',\n",
        " u'2day fm playing',\n",
        " u'2day fm playing im',\n",
        " u'2day fm playing im boat',\n",
        " u'2k9',\n",
        " u'2morrow',\n",
        " u'2morrow day',\n",
        " u'2morrow day smoking',\n",
        " u'2morrow day smoking don',\n",
        " u'2morrow day smoking don expect',\n",
        " u'2nd',\n",
        " u'2nd gen',\n",
        " u'2nd gen ipod',\n",
        " u'2nd gen ipod nano',\n",
        " u'2nd gen ipod nano inherited',\n",
        " u'2nd shift',\n",
        " u'2nd shift im',\n",
        " u'2nd shift im going',\n",
        " u'2nd shift im going miss',\n",
        " u'2night',\n",
        " u'2night 1st',\n",
        " u'2night 1st day',\n",
        " u'2night 1st day work',\n",
        " u'2night 1st day work sunday',\n",
        " u'2nite',\n",
        " u'2y36e',\n",
        " u'2y36e flowers',\n",
        " u'2y36e flowers falling',\n",
        " u'2y36e flowers falling dont',\n",
        " u'2y36e flowers falling dont camera',\n",
        " u'2y5xp',\n",
        " u'30',\n",
        " u'30 000',\n",
        " u'30 000 start',\n",
        " u'30 bbc2',\n",
        " u'30 bbc2 don',\n",
        " u'30 bbc2 don say',\n",
        " u'30 bbc2 don say raining',\n",
        " u'30 going',\n",
        " u'30 going bed',\n",
        " u'30 going bed shall',\n",
        " u'30 going bed shall ttyl',\n",
        " u'30 iphone',\n",
        " u'30 iphone talk',\n",
        " u'30 iphone talk keeping',\n",
        " u'30 iphone talk keeping waiting',\n",
        " u'30 mins',\n",
        " u'30 mins england',\n",
        " u'30 minutes',\n",
        " u'30 minutes boarding',\n",
        " u'30 minutes boarding passes',\n",
        " u'30 minutes boarding passes printed',\n",
        " u'3000',\n",
        " u'3000 hacked',\n",
        " u'3000 hacked wonder',\n",
        " u'3000 hacked wonder fuck',\n",
        " u'3000 hacked wonder fuck sold',\n",
        " u'3000 today',\n",
        " u'3000 today mystic',\n",
        " u'3000 today mystic silver',\n",
        " u'3000 today mystic silver copy',\n",
        " u'301',\n",
        " u'301 looking',\n",
        " u'301 looking forward',\n",
        " u'301 looking forward coming',\n",
        " u'30am',\n",
        " u'30am fuckin',\n",
        " u'30am fuckin tired',\n",
        " u'30am fuckin tired 24',\n",
        " u'30am fuckin tired 24 hours',\n",
        " u'30comau',\n",
        " u'30comau sec',\n",
        " u'30comau sec anniversary',\n",
        " u'30comau sec anniversary today',\n",
        " u'30pm',\n",
        " u'30pm im',\n",
        " u'30pm im gonna',\n",
        " u'30pm im gonna dinner',\n",
        " u'30pm im gonna dinner school',\n",
        " u'320',\n",
        " u'320 indonesia',\n",
        " u'320 indonesia states',\n",
        " u'32gb',\n",
        " u'32gb iphone',\n",
        " u'32gb iphone 3g',\n",
        " u'32gb iphone 3g unboxing',\n",
        " u'32gb iphone 3g unboxing need',\n",
        " u'33',\n",
        " u'33 night',\n",
        " u'33 night kidzz',\n",
        " u'33 reply',\n",
        " u'35',\n",
        " u'35 headphones',\n",
        " u'35 headphones ipod',\n",
        " u'35 headphones ipod need',\n",
        " u'35 headphones ipod need buy',\n",
        " u'360',\n",
        " u'360 http',\n",
        " u'360 http plurk',\n",
        " u'360 http plurk com',\n",
        " u'360 http plurk com yzkzb',\n",
        " u'360 news',\n",
        " u'360 news e3',\n",
        " u'360 news e3 bummed',\n",
        " u'360 news e3 bummed wait',\n",
        " u'360 premiums',\n",
        " u'360 premiums elite',\n",
        " u'360 premiums elite costly',\n",
        " u'360 rrod',\n",
        " u'360 rrod times',\n",
        " u'360 rrod times damn',\n",
        " u'360 rrod times damn micro',\n",
        " u'360 somebody',\n",
        " u'360 somebody humor',\n",
        " u'360 somebody humor pleeeeeeeeeeease',\n",
        " u'360 use',\n",
        " u'360 use twitter',\n",
        " u'360 use twitter tickers',\n",
        " u'360 use twitter tickers popups',\n",
        " u'360 words',\n",
        " u'360 words dead',\n",
        " u'360 words dead fb',\n",
        " u'371',\n",
        " u'371 followers',\n",
        " u'371 followers counting',\n",
        " u'371 followers counting girlfriend',\n",
        " u'38',\n",
        " u'38 london',\n",
        " u'38 london liverpool',\n",
        " u'38 london liverpool street',\n",
        " u'38 london liverpool street bit',\n",
        " u'395031',\n",
        " u'395031 says',\n",
        " u'395031 says stock',\n",
        " u'39am',\n",
        " u'39am getting',\n",
        " u'39am getting ready',\n",
        " u'39am getting ready school',\n",
        " u'39am getting ready school looking',\n",
        " u'3am',\n",
        " u'3am got',\n",
        " u'3am got headache',\n",
        " u'3am got headache yesterday',\n",
        " u'3am got headache yesterday night',\n",
        " u'3am mcdonalds',\n",
        " u'3am mcdonalds breakfast',\n",
        " u'3d',\n",
        " u'3d fantastic',\n",
        " u'3d fantastic ginormica',\n",
        " u'3d fantastic ginormica new',\n",
        " u'3d fantastic ginormica new favourite',\n",
        " u'3g',\n",
        " u'3g hasn',\n",
        " u'3g hasn activated',\n",
        " u'3g hasn activated 48',\n",
        " u'3g hasn activated 48 hours',\n",
        " u'3g keyboard',\n",
        " u'3g keyboard pre',\n",
        " u'3g keyboard pre small',\n",
        " u'3g keyboard pre small hands',\n",
        " u'3g test',\n",
        " u'3g test tired',\n",
        " u'3g test tired sacrificing',\n",
        " u'3g test tired sacrificing personal',\n",
        " u'3g unboxing',\n",
        " u'3g unboxing need',\n",
        " u'3g unboxing need place',\n",
        " u'3g unboxing need place later',\n",
        " u'3gs',\n",
        " u'3gs does',\n",
        " u'3gs does successfully',\n",
        " u'3gs does successfully repel',\n",
        " u'3gs does successfully repel fingerprints',\n",
        " u'3lzt1',\n",
        " u'3lzt1 way',\n",
        " u'3lzt1 way suscon',\n",
        " u'3mk',\n",
        " u'3rd',\n",
        " u'3rd anniversary',\n",
        " u'3rd anniversary mums',\n",
        " u'3rd anniversary mums death',\n",
        " u'3rd anniversary mums death cancer',\n",
        " u'3rd degree',\n",
        " u'3rd degree burns',\n",
        " u'3rd degree burns likely',\n",
        " u'3rd degree burns likely skin',\n",
        " u'3rd time',\n",
        " u'3rd time row',\n",
        " u'3rd time row stop',\n",
        " u'3rd time row stop cl',\n",
        " u'3turnoffwords',\n",
        " u'3turnoffwords quot',\n",
        " u'3turnoffwords quot ck',\n",
        " u'3turnoffwords quot ck lakers',\n",
        " u'3turnoffwords quot ck lakers quot',\n",
        " u'3ve',\n",
        " u'3ve taylor',\n",
        " u'3ve taylor swift',\n",
        " u'3ve taylor swift just',\n",
        " u'3ve taylor swift just amazing',\n",
        " u'3yr',\n",
        " u'3yr old',\n",
        " u'3yr old iphone',\n",
        " u'3yr old iphone phone',\n",
        " u'3yr old iphone phone sadly',\n",
        " u'3zgso',\n",
        " u'3zgso sad',\n",
        " u'40',\n",
        " u'40 feeding',\n",
        " u'40 feeding boy',\n",
        " u'40 feeding boy richie',\n",
        " u'40 feeding boy richie fever',\n",
        " u'400',\n",
        " u'400 quid',\n",
        " u'400 quid chance',\n",
        " u'404',\n",
        " u'404 great',\n",
        " u'41',\n",
        " u'41 carbs',\n",
        " u'41 carbs mexi',\n",
        " u'41 carbs mexi fry',\n",
        " u'42',\n",
        " u'42 oouuuch',\n",
        " u'420',\n",
        " u'420 laws',\n",
        " u'420 laws right',\n",
        " u'420 laws right sick',\n",
        " u'420 laws right sick privacy',\n",
        " u'439',\n",
        " u'439 calories',\n",
        " u'439 calories 28',\n",
        " u'439 calories 28 grams',\n",
        " u'439 calories 28 grams fat',\n",
        " u'447',\n",
        " u'45',\n",
        " u'45 man',\n",
        " u'45 man 50',\n",
        " u'45 man 50 sng',\n",
        " u'45 man 50 sng came',\n",
        " u'48',\n",
        " u'48 hours',\n",
        " u'49',\n",
        " u'49 lbs',\n",
        " u'49 lbs nice',\n",
        " u'49 lbs nice colorado',\n",
        " u'49 lbs nice colorado week',\n",
        " u'4am',\n",
        " u'4am woo',\n",
        " u'4pm',\n",
        " u'4pm 30pm',\n",
        " u'4pm 30pm im',\n",
        " u'4pm 30pm im gonna',\n",
        " u'4pm 30pm im gonna dinner',\n",
        " u'4th',\n",
        " u'4th quarter',\n",
        " u'4th quarter bout',\n",
        " u'4th quarter bout start',\n",
        " u'4th quarter bout start nother',\n",
        " u'4th trip',\n",
        " u'4th trip vegas',\n",
        " u'4th trip vegas week',\n",
        " u'4th trip vegas week happen',\n",
        " u'50',\n",
        " u'50 sng',\n",
        " u'50 sng came',\n",
        " u'50 sng came 4th',\n",
        " u'50 sng came 4th trip',\n",
        " u'51am',\n",
        " u'51am sydney',\n",
        " u'51am sydney having',\n",
        " u'51am sydney having midnight',\n",
        " u'51am sydney having midnight snacks',\n",
        " u'5248435',\n",
        " u'530',\n",
        " u'530 tommorrow',\n",
        " u'530 tommorrow good',\n",
        " u'530 tommorrow good times',\n",
        " u'536',\n",
        " u'536 page',\n",
        " u'536 page novel',\n",
        " u'536 page novel manuscript',\n",
        " u'536 page novel manuscript tonight',\n",
        " u'56m0y',\n",
        " u'56m0y really',\n",
        " u'56m0y really nice',\n",
        " u'56m0y really nice grettings',\n",
        " u'56m0y really nice grettings brazil',\n",
        " u'57',\n",
        " u'57 cents',\n",
        " u'57 cents today',\n",
        " u'57 cents today im',\n",
        " u'57 cents today im gunna',\n",
        " u'58',\n",
        " u'58 00',\n",
        " u'58 00 lol',\n",
        " u'58 00 lol ur',\n",
        " u'58 00 lol ur really',\n",
        " u'59',\n",
        " u'5am',\n",
        " u'5am gets',\n",
        " u'5am gets easier',\n",
        " u'5am gets easier man',\n",
        " u'5am gets easier man eyes',\n",
        " u'5am q13',\n",
        " u'5am q13 fox',\n",
        " u'5c9gs',\n",
        " u'5c9gs picture',\n",
        " u'5c9gs picture taylor',\n",
        " u'5c9gs picture taylor swift',\n",
        " u'5c9gs picture taylor swift really',\n",
        " u'5oh7',\n",
        " u'5oh7 going',\n",
        " u'5oh7 going miss',\n",
        " u'5oh7 going miss lebron',\n",
        " u'5oh7 going miss lebron kobe',\n",
        " u'5oll7',\n",
        " u'5oll7 board',\n",
        " u'5oll7 board mini',\n",
        " u'5oll7 board mini stored',\n",
        " u'5oll7 board mini stored minis',\n",
        " u'5pm',\n",
        " u'5pm emotions',\n",
        " u'5pm emotions gonna',\n",
        " u'5pm emotions gonna miss',\n",
        " u'5pm emotions gonna miss jackie',\n",
        " u'5th',\n",
        " u'5th june',\n",
        " u'5th june friday',\n",
        " u'5th june friday argh',\n",
        " u'5th june friday argh omg',\n",
        " u'5yr',\n",
        " u'5yr old',\n",
        " u'5yr old running',\n",
        " u'5yr old running fever',\n",
        " u'5yr old running fever week',\n",
        " u'5\\xba',\n",
        " u'5\\xba celsius',\n",
        " u'62',\n",
        " u'62 http',\n",
        " u'62 http bit',\n",
        " u'62 http bit ly',\n",
        " u'62 http bit ly 3zgso',\n",
        " u'62 http tumblr',\n",
        " u'62 http tumblr com',\n",
        " u'62 http tumblr com x5h25fy5j',\n",
        " u'62 spokesman',\n",
        " u'640km',\n",
        " u'640km northeast',\n",
        " u'640km northeast brazil',\n",
        " u'640km northeast brazil fernando',\n",
        " u'640km northeast brazil fernando norohna',\n",
        " u'642',\n",
        " u'6am',\n",
        " u'6am 9am',\n",
        " u'6am 9am yesterday',\n",
        " u'6am 9am yesterday problem',\n",
        " u'6am 9am yesterday problem starbucks',\n",
        " u'6am flight',\n",
        " u'6am flight leaving',\n",
        " u'6am flight leaving vegas',\n",
        " u'6am flight leaving vegas coming',\n",
        " u'6idya',\n",
        " u'6jw9f',\n",
        " u'6q1om',\n",
        " u'6q1om omg',\n",
        " u'6q1om omg jonas',\n",
        " u'6q1om omg jonas youtube',\n",
        " u'6q1om omg jonas youtube page',\n",
        " u'6r413',\n",
        " u'6r413 way',\n",
        " u'6r413 way vegas',\n",
        " u'6ubr9',\n",
        " u'6ubr9 woooho',\n",
        " u'6ubr9 woooho better',\n",
        " u'6ubr9 woooho better better',\n",
        " u'6ubr9 woooho better better watching',\n",
        " u'6vb49',\n",
        " u'6vb49 wow',\n",
        " u'6vb49 wow lance',\n",
        " u'6vb49 wow lance great',\n",
        " u'6vb49 wow lance great pic',\n",
        " u'70s',\n",
        " u'70s waiting',\n",
        " u'70s waiting headache',\n",
        " u'70s waiting headache away',\n",
        " u'70s waiting headache away lasted',\n",
        " u'72',\n",
        " u'74',\n",
        " u'74 error',\n",
        " u'74 error xbox',\n",
        " u'74 error xbox 360',\n",
        " u'74 error xbox 360 words',\n",
        " u'74 nd',\n",
        " u'74 nd send',\n",
        " u'74 nd send xbox',\n",
        " u'74 nd send xbox germany',\n",
        " u'75',\n",
        " u'75 spent',\n",
        " u'75 spent love',\n",
        " u'75 spent love frappuchino',\n",
        " u'75 spent love frappuchino lol',\n",
        " u'7e01t',\n",
        " u'7e01t ahh',\n",
        " u'7e01t ahh ve',\n",
        " u'7e01t ahh ve got',\n",
        " u'7e01t ahh ve got ipode',\n",
        " u'7gteh',\n",
        " u'7gteh wanting',\n",
        " u'7gteh wanting leave',\n",
        " u'7gteh wanting leave vegas',\n",
        " u'7gu8a',\n",
        " u'7gu8a hav',\n",
        " u'7gu8a hav wonder',\n",
        " u'7gu8a hav wonder obama',\n",
        " u'7gu8a hav wonder obama pro',\n",
        " u'7hr45mins',\n",
        " u'7hr45mins raised',\n",
        " u'7hr45mins raised 000gbp',\n",
        " u'7hr45mins raised 000gbp breast',\n",
        " u'7hr45mins raised 000gbp breast cancer',\n",
        " u'7mki1',\n",
        " u'7pf62',\n",
        " u'7pf62 quot',\n",
        " u'7pf62 quot lost',\n",
        " u'7pf62 quot lost melbourne',\n",
        " u'7pf62 quot lost melbourne quot',\n",
        " u'7pm',\n",
        " u'7pm sydney',\n",
        " u'7w83x',\n",
        " u'85',\n",
        " u'85 degree',\n",
        " u'85 degree weather',\n",
        " u'8gb',\n",
        " u'8gb ipod',\n",
        " u'8gb ipod touch',\n",
        " u'8gb ipod touch sale',\n",
        " u'8gb ipod touch sale reduced',\n",
        " u'8gb memory',\n",
        " u'8gb memory card',\n",
        " u'8gb memory card psp',\n",
        " u'8gb microsd',\n",
        " u'8gb microsd card',\n",
        " u'8gb microsd card en',\n",
        " u'8gb microsd card en route',\n",
        " u'8th',\n",
        " u'8th looking',\n",
        " u'8th looking forward',\n",
        " u'8th looking forward seeing',\n",
        " u'8th year',\n",
        " u'8th year brahhh',\n",
        " u'8yr',\n",
        " u'8yr old',\n",
        " u'8yr old child',\n",
        " u'8yr old child walk',\n",
        " u'8yr old child walk hello',\n",
        " u'96',\n",
        " u'96 degrees',\n",
        " u'96 degrees nashvegas',\n",
        " u'96 degrees nashvegas pool',\n",
        " u'96 male',\n",
        " u'96 male female',\n",
        " u'96 male female haven',\n",
        " u'96 male female haven gotten',\n",
        " u'98',\n",
        " u'98 hard',\n",
        " u'98 hard work',\n",
        " u'98 hard work luck',\n",
        " u'98 hard work luck youtube',\n",
        " u'98 yrs',\n",
        " u'98 yrs old',\n",
        " u'98 yrs old facebook',\n",
        " u'9am',\n",
        " u'9am yesterday',\n",
        " u'9am yesterday problem',\n",
        " u'9am yesterday problem starbucks',\n",
        " u'9am yesterday problem starbucks come',\n",
        " u'9th',\n",
        " u'9th isn',\n",
        " u'9th isn coming',\n",
        " u'9th isn coming soon',\n",
        " u'__',\n",
        " u'__ missed',\n",
        " u'__ missed told',\n",
        " u'__ missed told story',\n",
        " u'__ missed told story meeting',\n",
        " u'__________',\n",
        " u'__________ blank',\n",
        " u'__________ blank role',\n",
        " u'__________ blank role choice',\n",
        " u'_chelsea_marie',\n",
        " u'_chelsea_marie does',\n",
        " u'_chelsea_marie does target',\n",
        " u'_chelsea_marie does target ship',\n",
        " u'_chelsea_marie does target ship things',\n",
        " u'_despina',\n",
        " u'_despina friend',\n",
        " u'_despina friend took',\n",
        " u'_despina friend took obama',\n",
        " u'_despina friend took obama pin',\n",
        " u'_myana',\n",
        " u'_myana lt',\n",
        " u'aaaaahhhh',\n",
        " u'aaaaahhhh finally',\n",
        " u'aaaaahhhh finally stop',\n",
        " u'aaaaahhhh finally stop zippy',\n",
        " u'ab3dj',\n",
        " u'ab3dj poor',\n",
        " u'ab3dj poor cavs',\n",
        " u'ab3dj poor cavs hard',\n",
        " u'ab3dj poor cavs hard work',\n",
        " u'abandoning',\n",
        " u'abandoning capitalism',\n",
        " u'abandoning capitalism exchange',\n",
        " u'abandoning capitalism exchange obama',\n",
        " u'abandoning capitalism exchange obama flavored',\n",
        " u'abbie',\n",
        " u'abbie guess',\n",
        " u'abc',\n",
        " u'abc action',\n",
        " u'abc action news',\n",
        " u'abc action news family',\n",
        " u'abc action news family gary',\n",
        " u'abi',\n",
        " u'abi celebrating',\n",
        " u'abi celebrating family',\n",
        " u'abi celebrating family sister',\n",
        " u'abi celebrating family sister crazy',\n",
        " u'able',\n",
        " u'able 3rd',\n",
        " u'able backup',\n",
        " u'able backup months',\n",
        " u'able going',\n",
        " u'able going taylor',\n",
        " u'able going taylor swift',\n",
        " u'able going taylor swift concert',\n",
        " u'able play',\n",
        " u'able play bad',\n",
        " u'able play bad don',\n",
        " u'able play bad don psp',\n",
        " u'able ship',\n",
        " u'able ship continental',\n",
        " u'able ship continental want',\n",
        " u'able ship continental want hat',\n",
        " u'absolutely',\n",
        " u'absolutely like',\n",
        " u'absolutely like watching',\n",
        " u'absolutely like watching jonas',\n",
        " u'absolutely like watching jonas youtube',\n",
        " u'absolutely loved',\n",
        " u'absolutely loved jonas',\n",
        " u'absolutely loved jonas hahahaha',\n",
        " u'absolutely loved jonas hahahaha boys',\n",
        " u'absolutely loving',\n",
        " u'absoluty',\n",
        " u'absoluty shut',\n",
        " u'abt',\n",
        " u'abt kobe',\n",
        " u'abt kobe bc',\n",
        " u'abt kobe bc loveeeeeeee',\n",
        " u'abt kobe bc loveeeeeeee amp',\n",
        " u'abt sweet',\n",
        " u'abt sweet home',\n",
        " u'abt sweet home alabama',\n",
        " u'abt sweet home alabama ripped',\n",
        " u'abu',\n",
        " u'abu ghraib',\n",
        " u'abu ghraib quot',\n",
        " u'abu ghraib quot particularly',\n",
        " u'abu ghraib quot particularly sensational',\n",
        " u'abusing',\n",
        " u'abusing like',\n",
        " u'abusing like facebook',\n",
        " u'abusing like facebook don',\n",
        " u'abusing like facebook don real',\n",
        " u'ac',\n",
        " u'ac home',\n",
        " u'ac home hot',\n",
        " u'ac home hot work',\n",
        " u'acacia_scott',\n",
        " u'acacia_scott amp',\n",
        " u'acacia_scott amp anasanaturals',\n",
        " u'acacia_scott amp anasanaturals need',\n",
        " u'acacia_scott amp anasanaturals need pins',\n",
        " u'accent',\n",
        " u'accent sucks',\n",
        " u'accent sucks majorly',\n",
        " u'accept',\n",
        " u'accept defeat',\n",
        " u'accept defeat quot',\n",
        " u'accept fact',\n",
        " u'accept fact hayfever',\n",
        " u'accept fact walk',\n",
        " u'accept fact walk weekend',\n",
        " u'accept fact walk weekend end',\n",
        " u'accept family',\n",
        " u'accept family help',\n",
        " u'accept family help dead',\n",
        " u'accept praise',\n",
        " u'accept praise lose',\n",
        " u'accept praise lose accept',\n",
        " u'accept praise lose accept defeat',\n",
        " u'accessing',\n",
        " u'accessing ttb',\n",
        " u'accident',\n",
        " u'accident quot',\n",
        " u'accident quot pushing',\n",
        " u'accident quot pushing pushing',\n",
        " u'accident quot pushing pushing quot',\n",
        " u'accidental',\n",
        " u'accidental clicks',\n",
        " u'accidental clicks spent',\n",
        " u'accidental clicks spent hundreds',\n",
        " u'accidental clicks spent hundreds dollars',\n",
        " u'accidentally',\n",
        " u'accidentally deleted',\n",
        " u'accidentally deleted dance',\n",
        " u'accidentally deleted dance video',\n",
        " u'accidentally deleted dance video just',\n",
        " u'accidentally deleted reference',\n",
        " u'accidentally deleted reference management',\n",
        " u'accidentally deleted reference management assignment',\n",
        " u'accommodation',\n",
        " u'accommodation merkel',\n",
        " u'accommodation merkel german',\n",
        " u'accommodation merkel german chancellor',\n",
        " u'accommodation merkel german chancellor touristic',\n",
        " ...]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# need to set the output of this method to a variable\n",
      "# vector of all tweets\n",
      "\n",
      "print tweets_vectorizer.get_params(),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'binary': False, 'lowercase': True, 'stop_words': 'english', 'vocabulary': None, 'tokenizer': None, 'decode_error': u'strict', 'dtype': <type 'numpy.int64'>, 'charset_error': None, 'charset': None, 'analyzer': u'word', 'encoding': u'utf-8', 'ngram_range': (1, 5), 'max_df': 1.0, 'min_df': 1, 'max_features': None, 'input': u'content', 'strip_accents': None, 'token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b', 'preprocessor': None}\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a few helper functions\n",
      "def accuracy_report(_clf):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
      "    \n",
      "# a function to run some tests\n",
      "def analyze_review(testquote, vect, _clf):\n",
      "    print \"'%s' is judged by the clasifier to be...\" % (testquote)\n",
      "    testquote = vect.transform([testquote])\n",
      "    prob0 = _clf.predict_proba(testquote)[0][0]\n",
      "    prob1 = _clf.predict_proba(testquote)[0][1]\n",
      "    if (_clf.predict(testquote)[0] == 1):\n",
      "        print \"... a positive tweet with probability %02f.\" % prob1\n",
      "    else:\n",
      "        print \"... a negative tweet with probability %02f.\" % prob0\n",
      "    return(_clf.predict(testquote)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call transform to convert text to a bag of words\n",
      "# sparse matrix transformation\n",
      "# A sparse matrix is a matrix that allows special techniques to take \n",
      "# advantage of the large number of \"background\" (commonly zero) elements.\n",
      "\n",
      "x_transform = vectorizer.transform(tweets.tweet)\n",
      "x_transform.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(2034, 48070)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# same, but doing the fit and transform all in one go\n",
      "\n",
      "x_fit_transform = vectorizer.fit_transform(tweets.tweet)\n",
      "x_fit_transform.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(2034, 48070)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# these are the sparse matrix\n",
      "print x_fit_transform, x_transform"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 2087)\t1\n",
        "  (0, 15081)\t1\n",
        "  (0, 27315)\t1\n",
        "  (0, 2666)\t1\n",
        "  (0, 45665)\t1\n",
        "  (0, 2092)\t1\n",
        "  (0, 15221)\t1\n",
        "  (0, 27319)\t1\n",
        "  (0, 2667)\t1\n",
        "  (0, 2093)\t1\n",
        "  (0, 15222)\t1\n",
        "  (0, 27320)\t1\n",
        "  (0, 2094)\t1\n",
        "  (0, 15223)\t1\n",
        "  (0, 2095)\t1\n",
        "  (1, 24940)\t1\n",
        "  (1, 36037)\t1\n",
        "  (1, 14711)\t1\n",
        "  (1, 42374)\t1\n",
        "  (1, 6962)\t1\n",
        "  (1, 31724)\t1\n",
        "  (1, 23126)\t1\n",
        "  (1, 3187)\t1\n",
        "  (1, 39044)\t1\n",
        "  (1, 12487)\t1\n",
        "  :\t:\n",
        "  (2033, 25835)\t1\n",
        "  (2033, 22744)\t1\n",
        "  (2033, 46432)\t1\n",
        "  (2033, 22450)\t1\n",
        "  (2033, 28173)\t1\n",
        "  (2033, 21717)\t1\n",
        "  (2033, 41108)\t1\n",
        "  (2033, 40310)\t1\n",
        "  (2033, 18146)\t1\n",
        "  (2033, 16603)\t1\n",
        "  (2033, 25836)\t1\n",
        "  (2033, 22745)\t1\n",
        "  (2033, 46433)\t1\n",
        "  (2033, 22451)\t1\n",
        "  (2033, 28174)\t1\n",
        "  (2033, 21718)\t1\n",
        "  (2033, 41109)\t1\n",
        "  (2033, 18147)\t1\n",
        "  (2033, 16604)\t1\n",
        "  (2033, 25837)\t1\n",
        "  (2033, 22746)\t1\n",
        "  (2033, 46434)\t1\n",
        "  (2033, 22452)\t1\n",
        "  (2033, 28175)\t1\n",
        "  (2033, 21719)\t1   (0, 2087)\t1\n",
        "  (0, 2092)\t1\n",
        "  (0, 2093)\t1\n",
        "  (0, 2094)\t1\n",
        "  (0, 2095)\t1\n",
        "  (0, 2666)\t1\n",
        "  (0, 2667)\t1\n",
        "  (0, 15081)\t1\n",
        "  (0, 15221)\t1\n",
        "  (0, 15222)\t1\n",
        "  (0, 15223)\t1\n",
        "  (0, 27315)\t1\n",
        "  (0, 27319)\t1\n",
        "  (0, 27320)\t1\n",
        "  (0, 45665)\t1\n",
        "  (1, 3187)\t1\n",
        "  (1, 3267)\t1\n",
        "  (1, 3268)\t1\n",
        "  (1, 3269)\t1\n",
        "  (1, 3270)\t1\n",
        "  (1, 3989)\t1\n",
        "  (1, 3994)\t1\n",
        "  (1, 5499)\t1\n",
        "  (1, 6962)\t1\n",
        "  (1, 6975)\t1\n",
        "  :\t:\n",
        "  (2033, 22746)\t1\n",
        "  (2033, 25833)\t1\n",
        "  (2033, 25834)\t1\n",
        "  (2033, 25835)\t1\n",
        "  (2033, 25836)\t1\n",
        "  (2033, 25837)\t1\n",
        "  (2033, 28171)\t1\n",
        "  (2033, 28172)\t1\n",
        "  (2033, 28173)\t1\n",
        "  (2033, 28174)\t1\n",
        "  (2033, 28175)\t1\n",
        "  (2033, 40281)\t1\n",
        "  (2033, 40309)\t1\n",
        "  (2033, 40310)\t1\n",
        "  (2033, 41064)\t1\n",
        "  (2033, 41107)\t1\n",
        "  (2033, 41108)\t1\n",
        "  (2033, 41109)\t1\n",
        "  (2033, 46395)\t1\n",
        "  (2033, 46431)\t1\n",
        "  (2033, 46432)\t1\n",
        "  (2033, 46433)\t1\n",
        "  (2033, 46434)\t1\n",
        "  (2033, 47398)\t1\n",
        "  (2033, 47403)\t1\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Examine the Dependent variable we are predicting\n",
      "tweets.polarity.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "0    1402\n",
        "4     632\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# transform dependent into binary\n",
      "Y = (tweets.polarity == 4).values.astype(np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "(2034,)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(Y), len(Y[Y==1]), len(Y[Y==0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2034 632 1402\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split dataset into testing and training\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(x_transform, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xtrain, xtest, len(ytrain), len(ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "(<1525x48070 sparse matrix of type '<type 'numpy.int64'>'\n",
        " \twith 44643 stored elements in Compressed Sparse Row format>,\n",
        " <509x48070 sparse matrix of type '<type 'numpy.int64'>'\n",
        " \twith 15289 stored elements in Compressed Sparse Row format>,\n",
        " 1525,\n",
        " 509)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit classification using MultinomialNB\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "fitmt = MultinomialNB().fit(xtrain, ytrain)\n",
      "print fitmt.score(xtrain, ytrain)\n",
      "print fitmt.score(xtest, ytest)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.998032786885\n",
        "0.669941060904\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit classification using BernoulliNB\n",
      "\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "\n",
      "fitbm = BernoulliNB().fit(xtrain, ytrain)\n",
      "print fitbm.score(xtrain, ytrain)\n",
      "print fitbm.score(xtest, ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.764590163934\n",
        "0.715127701375\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit classification using Logistic Regression (not Naive Bayes)\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "fitlg = LogisticRegression().fit(xtrain, ytrain)\n",
      "print fitlg.score(xtrain, ytrain)\n",
      "print fitlg.score(xtest, ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.998032786885\n",
        "0.834970530452\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# conclusion, it looks like logistic regression fits better \n",
      "# than Naive Bayes for both Bernoulli and Multinomial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# take a look at the following two tweets, classify according \n",
      "# to our models\n",
      "\n",
      "tweet1 = \"@DataDAVE thanks for the awesome twitter dataset!!\"\n",
      "tweet2 = \"I just don't understand lesso!??!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rename tweet1 to create a new variable\n",
      "tweet1_vec = tweets_vectorizer.transform([tweet1])\n",
      "tweet2_vec = tweets_vectorizer.transform([tweet2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# under the logistic regresion model...\n",
      "\n",
      "# tweet1 could be a positive tweet with prob = 0.85\n",
      "print fitlg.predict(tweet1_vec)[0]\n",
      "\n",
      "# tweet1 could be a negative tweet with prob = 0.15\n",
      "print fitlg.predict_proba(tweet1_vec[0])\n",
      "\n",
      "# tweet2 could be a positive tweet with prob = 0.12\n",
      "print fitlg.predict(tweet2_vec)[0]\n",
      "\n",
      "# tweet2 could be a negative tweet with prob = 0.88\n",
      "print fitlg.predict_proba(tweet2_vec[0])\n",
      "\n",
      "print 'fit logistic regression:'\n",
      "analyze_review(tweet1, tweets_vectorizer, fitlg)\n",
      "analyze_review(tweet2, tweets_vectorizer, fitlg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "[[ 0.14918535  0.85081465]]\n",
        "0\n",
        "[[ 0.88253754  0.11746246]]\n",
        "fit logistic regression:\n",
        "'@DataDAVE thanks for the awesome twitter dataset!!' is judged by the clasifier to be...\n",
        "... a positive tweet with probability 0.850815.\n",
        "'I just don't understand lesso!??!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 0.882538.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# under the multinomial naive bayes model...\n",
      "\n",
      "# tweet1 could be a positive tweet with prob = 0.95\n",
      "print fitmt.predict(tweet1_vec)[0]\n",
      "\n",
      "# tweet1 could be a negative tweet with prob = 0.05\n",
      "print fitmt.predict_proba(tweet1_vec[0])\n",
      "\n",
      "# tweet2 could be a positive tweet with prob = 0.008\n",
      "print fitmt.predict(tweet2_vec)[0]\n",
      "\n",
      "# tweet2 could be a negative tweet with prob = 0.992\n",
      "print fitmt.predict_proba(tweet2_vec[0])\n",
      "\n",
      "print 'fit multinomial naive bayes:'\n",
      "analyze_review(tweet1, tweets_vectorizer, fitmt)\n",
      "analyze_review(tweet2, tweets_vectorizer, fitmt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "[[ 0.04134471  0.95865529]]\n",
        "0\n",
        "[[ 0.99198724  0.00801276]]\n",
        "fit multinomial naive bayes:\n",
        "'@DataDAVE thanks for the awesome twitter dataset!!' is judged by the clasifier to be...\n",
        "... a positive tweet with probability 0.958655.\n",
        "'I just don't understand lesso!??!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 0.991987.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# under the Bernoulli naive bayes model...\n",
      "\n",
      "# tweet1 could be a positive tweet with prob = 1\n",
      "print fitbm.predict(tweet1_vec)[0]\n",
      "\n",
      "# tweet1 could be a negative tweet with prob = 0\n",
      "print fitbm.predict_proba(tweet1_vec[0])\n",
      "\n",
      "# tweet2 could be a positive tweet with prob = 0\n",
      "print fitbm.predict(tweet2_vec)[0]\n",
      "\n",
      "# tweet2 could be a negative tweet with prob = 1\n",
      "print fitbm.predict_proba(tweet2_vec[0])\n",
      "\n",
      "print 'fit bernoulli naive bayes:'\n",
      "analyze_review(tweet1, tweets_vectorizer, fitbm)\n",
      "analyze_review(tweet2, tweets_vectorizer, fitbm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "[[  1.00000000e+00   3.41026094e-22]]\n",
        "0\n",
        "[[  1.00000000e+00   3.51550011e-25]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit bernoulli naive bayes:\n",
        "'@DataDAVE thanks for the awesome twitter dataset!!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 1.000000."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "'I just don't understand lesso!??!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 1.000000."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a few more under the hood look at the models...\n",
      "fitlg\n",
      "fitlg.coef_\n",
      "fitlg.decision_function\n",
      "fitlg.fit\n",
      "fitlg.fit_intercept\n",
      "fitlg.fit_transform\n",
      "fitlg.C\n",
      "fitlg.get_params\n",
      "fitlg.get_params()\n",
      "fitlg.multi_class\n",
      "fitlg.transform\n",
      "fitlg.verbose = True\n",
      "fitlg.predict??"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}