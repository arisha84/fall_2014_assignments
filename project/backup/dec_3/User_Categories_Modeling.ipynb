{
 "metadata": {
  "name": "",
  "signature": "sha256:1abbe6a1e041247888902d6477ccb0a02a3029c0a0c6ec89968e28495e397a50"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn\n",
      "import sklearn.linear_model as lm\n",
      "import sklearn.cross_validation as cv\n",
      "import sklearn.grid_search as gs\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split, Bootstrap\n",
      "from sklearn.datasets import make_blobs\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import RandomizedLogisticRegression\n",
      "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from IPython.display import Image\n",
      "from sklearn.decomposition import PCA\n",
      "import sklearn.grid_search as gs\n",
      "conf_matrix_image = Image(url='https://computersciencesource.files.wordpress.com/2010/01/conmat.png')\n",
      "%matplotlib inline\n",
      "#%pylab inline\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load & Cleanup Data: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('/vagrant/829/filtered_output_for_campaign_829.csv')\n",
      "df = data.fillna(0)\n",
      "df = df.drop(['DATE','USER ID', 'CAMPAIGN ID', 'Completer'], axis=1)\n",
      "tmp = df['Exelate 2788 - Auto - Buyers - Make:Wiesmann']\n",
      "\n",
      "df = df.ix[:,(df != 0).any(axis=0)] ## remove all columns with all zeros\n",
      "df = df.ix[(df != 0).any(axis=1),:] ## remove all rows with all zeros"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Visualize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Exelate 10 - General Interest - Auto Enthusiasts</th>\n",
        "      <th>Exelate 1006 - General Interest - Green Living</th>\n",
        "      <th>Exelate 1007 - Politics - Political Junkies</th>\n",
        "      <th>Exelate 10082 - Finance and Insurance - Mortgages - Mortgage Hyper-Intent</th>\n",
        "      <th>Exelate 1017 - Shopping - Mobile - Carrier: AT&amp;T</th>\n",
        "      <th>Exelate 10179 - Travel - Departure - Europe</th>\n",
        "      <th>Exelate 1018 - Shopping - Mobile - Carrier: T-Mobile</th>\n",
        "      <th>Exelate 10180 - Travel - Departure - North America</th>\n",
        "      <th>Exelate 1019 - Shopping - Mobile - Carrier: Sprint</th>\n",
        "      <th>Exelate 1020 - Shopping - Mobile - Carrier: Verizon</th>\n",
        "      <th>...</th>\n",
        "      <th>Exelate 9321 - Auto - Buyers - Make:Tesla - Model S</th>\n",
        "      <th>Exelate 9638 - Finance and Insurance - Auto Intenders</th>\n",
        "      <th>Exelate 9969 - Finance and Insurance - Banking - Checking and Savings</th>\n",
        "      <th>Exelate 9970 - Finance and Insurance - Credit Cards - Small Business</th>\n",
        "      <th>Exelate 9989 - CPG - Dish and Dishwasher Detergent</th>\n",
        "      <th>Exelate 3211 - Services - Personal Services and Care - Children Daycare</th>\n",
        "      <th>Exelate 5106 - Entertainment - Music - Jazz/Blues</th>\n",
        "      <th>Retargeting</th>\n",
        "      <th>Clicker</th>\n",
        "      <th>PIA</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "      <td> 37645.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>     0.207757</td>\n",
        "      <td>     0.176757</td>\n",
        "      <td>     0.304715</td>\n",
        "      <td>     0.029539</td>\n",
        "      <td>     0.000213</td>\n",
        "      <td>     0.000372</td>\n",
        "      <td>     0.000080</td>\n",
        "      <td>     0.027069</td>\n",
        "      <td>     0.000106</td>\n",
        "      <td>     0.000478</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000372</td>\n",
        "      <td>     0.212777</td>\n",
        "      <td>     0.242130</td>\n",
        "      <td>     0.145092</td>\n",
        "      <td>     0.033922</td>\n",
        "      <td>     0.000027</td>\n",
        "      <td>     0.000027</td>\n",
        "      <td>     0.291088</td>\n",
        "      <td>     0.001381</td>\n",
        "      <td>     0.292044</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>     0.405707</td>\n",
        "      <td>     0.381468</td>\n",
        "      <td>     0.460293</td>\n",
        "      <td>     0.169314</td>\n",
        "      <td>     0.014576</td>\n",
        "      <td>     0.019281</td>\n",
        "      <td>     0.008927</td>\n",
        "      <td>     0.162286</td>\n",
        "      <td>     0.010308</td>\n",
        "      <td>     0.021862</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.019281</td>\n",
        "      <td>     0.409277</td>\n",
        "      <td>     0.428379</td>\n",
        "      <td>     0.352199</td>\n",
        "      <td>     0.181031</td>\n",
        "      <td>     0.005154</td>\n",
        "      <td>     0.005154</td>\n",
        "      <td>     0.454270</td>\n",
        "      <td>     0.037141</td>\n",
        "      <td>     0.454709</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 1169 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "       Exelate 10 - General Interest - Auto Enthusiasts  \\\n",
        "count                                      37645.000000   \n",
        "mean                                           0.207757   \n",
        "std                                            0.405707   \n",
        "min                                            0.000000   \n",
        "25%                                            0.000000   \n",
        "50%                                            0.000000   \n",
        "75%                                            0.000000   \n",
        "max                                            1.000000   \n",
        "\n",
        "       Exelate 1006 - General Interest - Green Living  \\\n",
        "count                                    37645.000000   \n",
        "mean                                         0.176757   \n",
        "std                                          0.381468   \n",
        "min                                          0.000000   \n",
        "25%                                          0.000000   \n",
        "50%                                          0.000000   \n",
        "75%                                          0.000000   \n",
        "max                                          1.000000   \n",
        "\n",
        "       Exelate 1007 - Politics - Political Junkies  \\\n",
        "count                                 37645.000000   \n",
        "mean                                      0.304715   \n",
        "std                                       0.460293   \n",
        "min                                       0.000000   \n",
        "25%                                       0.000000   \n",
        "50%                                       0.000000   \n",
        "75%                                       1.000000   \n",
        "max                                       1.000000   \n",
        "\n",
        "       Exelate 10082 - Finance and Insurance - Mortgages - Mortgage Hyper-Intent  \\\n",
        "count                                       37645.000000                           \n",
        "mean                                            0.029539                           \n",
        "std                                             0.169314                           \n",
        "min                                             0.000000                           \n",
        "25%                                             0.000000                           \n",
        "50%                                             0.000000                           \n",
        "75%                                             0.000000                           \n",
        "max                                             1.000000                           \n",
        "\n",
        "       Exelate 1017 - Shopping - Mobile - Carrier: AT&T  \\\n",
        "count                                      37645.000000   \n",
        "mean                                           0.000213   \n",
        "std                                            0.014576   \n",
        "min                                            0.000000   \n",
        "25%                                            0.000000   \n",
        "50%                                            0.000000   \n",
        "75%                                            0.000000   \n",
        "max                                            1.000000   \n",
        "\n",
        "       Exelate 10179 - Travel - Departure - Europe  \\\n",
        "count                                 37645.000000   \n",
        "mean                                      0.000372   \n",
        "std                                       0.019281   \n",
        "min                                       0.000000   \n",
        "25%                                       0.000000   \n",
        "50%                                       0.000000   \n",
        "75%                                       0.000000   \n",
        "max                                       1.000000   \n",
        "\n",
        "       Exelate 1018 - Shopping - Mobile - Carrier: T-Mobile  \\\n",
        "count                                       37645.000000      \n",
        "mean                                            0.000080      \n",
        "std                                             0.008927      \n",
        "min                                             0.000000      \n",
        "25%                                             0.000000      \n",
        "50%                                             0.000000      \n",
        "75%                                             0.000000      \n",
        "max                                             1.000000      \n",
        "\n",
        "       Exelate 10180 - Travel - Departure - North America  \\\n",
        "count                                       37645.000000    \n",
        "mean                                            0.027069    \n",
        "std                                             0.162286    \n",
        "min                                             0.000000    \n",
        "25%                                             0.000000    \n",
        "50%                                             0.000000    \n",
        "75%                                             0.000000    \n",
        "max                                             1.000000    \n",
        "\n",
        "       Exelate 1019 - Shopping - Mobile - Carrier: Sprint  \\\n",
        "count                                       37645.000000    \n",
        "mean                                            0.000106    \n",
        "std                                             0.010308    \n",
        "min                                             0.000000    \n",
        "25%                                             0.000000    \n",
        "50%                                             0.000000    \n",
        "75%                                             0.000000    \n",
        "max                                             1.000000    \n",
        "\n",
        "       Exelate 1020 - Shopping - Mobile - Carrier: Verizon  \\\n",
        "count                                       37645.000000     \n",
        "mean                                            0.000478     \n",
        "std                                             0.021862     \n",
        "min                                             0.000000     \n",
        "25%                                             0.000000     \n",
        "50%                                             0.000000     \n",
        "75%                                             0.000000     \n",
        "max                                             1.000000     \n",
        "\n",
        "                              ...                           \\\n",
        "count                         ...                            \n",
        "mean                          ...                            \n",
        "std                           ...                            \n",
        "min                           ...                            \n",
        "25%                           ...                            \n",
        "50%                           ...                            \n",
        "75%                           ...                            \n",
        "max                           ...                            \n",
        "\n",
        "       Exelate 9321 - Auto - Buyers - Make:Tesla - Model S  \\\n",
        "count                                       37645.000000     \n",
        "mean                                            0.000372     \n",
        "std                                             0.019281     \n",
        "min                                             0.000000     \n",
        "25%                                             0.000000     \n",
        "50%                                             0.000000     \n",
        "75%                                             0.000000     \n",
        "max                                             1.000000     \n",
        "\n",
        "       Exelate 9638 - Finance and Insurance - Auto Intenders  \\\n",
        "count                                       37645.000000       \n",
        "mean                                            0.212777       \n",
        "std                                             0.409277       \n",
        "min                                             0.000000       \n",
        "25%                                             0.000000       \n",
        "50%                                             0.000000       \n",
        "75%                                             0.000000       \n",
        "max                                             1.000000       \n",
        "\n",
        "       Exelate 9969 - Finance and Insurance - Banking - Checking and Savings  \\\n",
        "count                                       37645.000000                       \n",
        "mean                                            0.242130                       \n",
        "std                                             0.428379                       \n",
        "min                                             0.000000                       \n",
        "25%                                             0.000000                       \n",
        "50%                                             0.000000                       \n",
        "75%                                             0.000000                       \n",
        "max                                             1.000000                       \n",
        "\n",
        "       Exelate 9970 - Finance and Insurance - Credit Cards - Small Business  \\\n",
        "count                                       37645.000000                      \n",
        "mean                                            0.145092                      \n",
        "std                                             0.352199                      \n",
        "min                                             0.000000                      \n",
        "25%                                             0.000000                      \n",
        "50%                                             0.000000                      \n",
        "75%                                             0.000000                      \n",
        "max                                             1.000000                      \n",
        "\n",
        "       Exelate 9989 - CPG - Dish and Dishwasher Detergent  \\\n",
        "count                                       37645.000000    \n",
        "mean                                            0.033922    \n",
        "std                                             0.181031    \n",
        "min                                             0.000000    \n",
        "25%                                             0.000000    \n",
        "50%                                             0.000000    \n",
        "75%                                             0.000000    \n",
        "max                                             1.000000    \n",
        "\n",
        "       Exelate 3211 - Services - Personal Services and Care - Children Daycare  \\\n",
        "count                                       37645.000000                         \n",
        "mean                                            0.000027                         \n",
        "std                                             0.005154                         \n",
        "min                                             0.000000                         \n",
        "25%                                             0.000000                         \n",
        "50%                                             0.000000                         \n",
        "75%                                             0.000000                         \n",
        "max                                             1.000000                         \n",
        "\n",
        "       Exelate 5106 - Entertainment - Music - Jazz/Blues   Retargeting  \\\n",
        "count                                       37645.000000  37645.000000   \n",
        "mean                                            0.000027      0.291088   \n",
        "std                                             0.005154      0.454270   \n",
        "min                                             0.000000      0.000000   \n",
        "25%                                             0.000000      0.000000   \n",
        "50%                                             0.000000      0.000000   \n",
        "75%                                             0.000000      1.000000   \n",
        "max                                             1.000000      1.000000   \n",
        "\n",
        "            Clicker           PIA  \n",
        "count  37645.000000  37645.000000  \n",
        "mean       0.001381      0.292044  \n",
        "std        0.037141      0.454709  \n",
        "min        0.000000      0.000000  \n",
        "25%        0.000000      0.000000  \n",
        "50%        0.000000      0.000000  \n",
        "75%        0.000000      1.000000  \n",
        "max        1.000000      1.000000  \n",
        "\n",
        "[8 rows x 1169 columns]"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_df_row = df.sum(axis=1) ## sum of each row\n",
      "plt.hist(sum_df_row,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "(array([  1.62690000e+04,   5.07100000e+03,   3.53000000e+03,\n",
        "          2.77500000e+03,   2.40500000e+03,   2.18400000e+03,\n",
        "          1.66600000e+03,   1.23300000e+03,   8.56000000e+02,\n",
        "          5.69000000e+02,   3.98000000e+02,   2.37000000e+02,\n",
        "          1.86000000e+02,   1.07000000e+02,   5.20000000e+01,\n",
        "          3.40000000e+01,   3.40000000e+01,   1.80000000e+01,\n",
        "          1.20000000e+01,   9.00000000e+00]),\n",
        " array([   1. ,   22.4,   43.8,   65.2,   86.6,  108. ,  129.4,  150.8,\n",
        "         172.2,  193.6,  215. ,  236.4,  257.8,  279.2,  300.6,  322. ,\n",
        "         343.4,  364.8,  386.2,  407.6,  429. ]),\n",
        " <a list of 20 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f9bd9bf7d50>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_df_col = df.sum(axis=0) ## sum of each column\n",
      "plt.hist(sum_df_col,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "(array([ 779.,  109.,   70.,   56.,   39.,   28.,   22.,   15.,   16.,\n",
        "          10.,    7.,    5.,    4.,    6.,    0.,    1.,    1.,    0.,\n",
        "           0.,    1.]),\n",
        " array([  1.00000000e+00,   1.26005000e+03,   2.51910000e+03,\n",
        "          3.77815000e+03,   5.03720000e+03,   6.29625000e+03,\n",
        "          7.55530000e+03,   8.81435000e+03,   1.00734000e+04,\n",
        "          1.13324500e+04,   1.25915000e+04,   1.38505500e+04,\n",
        "          1.51096000e+04,   1.63686500e+04,   1.76277000e+04,\n",
        "          1.88867500e+04,   2.01458000e+04,   2.14048500e+04,\n",
        "          2.26639000e+04,   2.39229500e+04,   2.51820000e+04]),\n",
        " <a list of 20 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkSZIkSZIkSZIkSZIkzVT/DyYph3TX8KUmAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f9bd81ebb50>"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spy(df.ix[:1000,:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f9bd96dea50>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAEACAYAAAAN5psFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f9bd7f22c50>"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "I want to find a correlation between exelate categories (+ one eyeview category - completer) and PIA. \n",
      "PIA is defined is defined as a user who either visited the site\n",
      "(the retargeting column) or clicked on the ad. Thus, my y variable is PIA column and my X is all other categories (excluding PIA, retargeting and clicker)\n",
      "                                                                                                                   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = df['PIA']\n",
      "x = df.drop(['PIA','Retargeting', 'Clicker'], axis=1)\n",
      "y_df = pd.DataFrame(y, columns = ['PIA'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Remove Correlated features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = x.corr().abs()\n",
      "\n",
      "#s = c.unstack()\n",
      "#so = s.order(kind=\"quicksort\")\n",
      "#highly_correlated = so[so < 1][so > 0.99]\n",
      "#highly_correlated.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Detect_Colinearity (corr_matrix,corr_threshold):\n",
      "    col_set =set()\n",
      "    for col in corr_matrix.columns:\n",
      "        column = corr_matrix.loc[:,col][corr_matrix.loc[:,col]!=1]\n",
      "        if max(column) > corr_threshold:\n",
      "            tup = tuple(sort ((np.argmax(column), col)))\n",
      "            col_set.add(tup)\n",
      "            #print np.argmax(column), \" max correlation with \" ,col ,\" is \", max(column)\n",
      "    return col_set\n",
      "col_set = Detect_Colinearity(c,0.9)\n",
      "len (col_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "50"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(37645, 1166)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove one of the pair features that are highly correlated\n",
      "for colA, cloB in col_set:\n",
      "    print colA\n",
      "    try:\n",
      "        tmp = x.pop(colA)\n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exelate 530 - Travel - Destination - South America\n",
        "Exelate 6621 - Propensity - Travel - Cruise - Caribbean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1436 - Services - Restaurants - Pizza"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 530 - Travel - Destination - South America"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 7794 - Propensity - Auto - Budget - $50K-$74K\n",
        "Exelate 12729 - Shopping - Retail - Brands - Walgreens"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16133 - Interest - TV Viewership - Categories - News"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 6614 - Propensity - Travel - Cruise - Family"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16133 - Interest - TV Viewership - Categories - News"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 54 - Travel - Destination - Europe\n",
        "Exelate 54 - Travel - Destination - Europe"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 6622 - Propensity - Travel - Resort - Caribbean\n",
        "Exelate 13371 - Sports - Rugby"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1132 - Services - Personal Services and Care"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 6299 - Travel - Family Trips"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1436 - Services - Restaurants - Pizza"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1436 - Services - Restaurants - Pizza\n",
        "Exelate 16125 - Interest - TV Viewership - Categories - Comedy\n",
        "Exelate 12729 - Shopping - Retail - Brands - Walgreens"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 7734 - CPG - Health and Beauty - Fragrances\n",
        "Exelate 1436 - Services - Restaurants - Pizza"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 6622 - Propensity - Travel - Resort - Caribbean\n",
        "Exelate 16084 - Auto Owners - By Type - Luxury Car\n",
        "Exelate 1436 - Services - Restaurants - Pizza"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1956 - Auto - Buyers - Make:Mini - Cooper\n",
        "Exelate 16127 - Interest - TV Viewership - Categories - Family"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16124 - Interest - TV Viewership - Categories - Award Shows"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16135 - Interest - TV Viewership - Categories - Drama"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 217 - Shopping - Sports and Recreation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16140 - Interest - TV Viewership - Categories - Sports"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1339 - Travel - Destination - North America - US - Michigan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16132 - Interest - TV Viewership - Categories - DIY"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16137 - Interest - TV Viewership - Categories - Reality TV"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16141 - Interest - TV Viewership - Categories - Reality Competition"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1289 - Events - Arts and Science"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 63 - Travel - Destination - North America - US - Nevada - Las Vegas LAS"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1660 - Auto - Buyers - Make:RAM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 5448 - Purchase Behaviors - Shopping - Entertainment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 6644 - Propensity - Auto - Lease"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 5408 - Purchase Behaviors - Shopping - Books"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16139 - Interest - TV Viewership - Categories - Sci-Fi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 7795 - Propensity - Auto - Budget - $75K+"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 6168 - Travel - Accommodation - Four Star"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 16125 - Interest - TV Viewership - Categories - Comedy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 1436 - Services - Restaurants - Pizza\n",
        "Exelate 7126 - Auto Owners - Motorcycle - Domestic\n",
        "Exelate 1296 - Events - Gift Giving Holidays"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 3196 - Services - Arts and Entertainment - Night Life"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 13371 - Sports - Rugby"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Exelate 55 - Travel - Destination - Central America - Mexico - Caribbean\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "(37645, 1128)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "\n",
      "Try different Models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import svm\n",
      "\n",
      "\n",
      "classifiers = {#'Logistic': LogisticRegression(),\n",
      "               #'BernoulliNB': BernoulliNB(alpha=82.864277285468418),\n",
      "               'BernoulliNB': BernoulliNB(),\n",
      "               #'extra_trees_clf': ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=1, random_state=0),\n",
      "               #'GaussianNB':GaussianNB(),               \n",
      "               #'KNeighbors': KNeighborsClassifier(),\n",
      "               #'RandomForest': RandomForestClassifier(),\n",
      "               #'RandomizedLogisticalRegression': RandomizedLogisticRegression(), # Todo: add this\n",
      "               #'Decision': DecisionTreeClassifier()\n",
      "               #'SVC' :svm.SVC(),\n",
      "               #svm.\n",
      "               #'GSD' : SGDClassifier()\n",
      "               }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def runSingleClassifier(x_train, y_train, x_test, y_test, clf):\n",
      "    clf.fit(X_train,y_train)         \n",
      "    y_hat = clf.predict(X_test)\n",
      "    score_roc_auc = roc_auc_score(y_test, y_hat)        \n",
      "    score = clf.score(X_test, y_test)                \n",
      "    return score, score_roc_auc, y_hat   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def runClassifier(X,Y, clf, times): \n",
      "    sum_scores = 0.0\n",
      "    sum_scores_roc_auc = 0.0\n",
      "    conf_matrix = None\n",
      "    \n",
      "    for i in range(times):\n",
      "         (X_train, X_test,\n",
      "         y_train, y_test) = cv.train_test_split(X, Y,\n",
      "                                            test_size=.1)\n",
      "         clf.fit(X_train,y_train)\n",
      "         \n",
      "         y_hat = clf.predict(X_test)\n",
      "         sum_scores_roc_auc += roc_auc_score(y_test, y_hat)        \n",
      "         sum_scores += clf.score(X_test, y_test)\n",
      "         if (conf_matrix == None):                 \n",
      "                conf_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
      "         else: \n",
      "                conf_matrix += metrics.confusion_matrix(y_test, y_hat)       \n",
      "                \n",
      "         #print \"%s had an accuracy score of %0.2f\"% (name, score)            \n",
      "    return sum_scores / times, sum_scores_roc_auc / times , conf_matrix / times\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_classifiers(X,Y,times):\n",
      "    for name, clf in classifiers.items():\n",
      "        score, score_roc_auc, conf_matrix = runClassifier(X,Y,clf, times)   \n",
      "        print \"%s had an average accuracy score of %0.2f, and roc_auc score of %0.2f\"% (name, score, score_roc_auc)\n",
      "        print \"confusion matrix: \"\n",
      "        print conf_matrix\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "(37645, 1128)"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_classifiers(x,y,2) ## regular bernoli"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB had an average accuracy score of 0.65, and roc_auc score of 0.60\n",
        "confusion matrix: \n",
        "[[1925  743]\n",
        " [ 562  534]]\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_classifiers(x,y,3) ## bernoli with alpha = 82"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB had an average accuracy score of 0.66, and roc_auc score of 0.60\n",
        "confusion matrix: \n",
        "[[1976  671]\n",
        " [ 606  510]]\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_classifiers(x,y,2) ## Todo: display only roc_auc score, this is what i'm intrested in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
        "  VisibleDeprecationWarning)\n",
        "-c:15: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RandomForest had an average accuracy score of 0.71, and roc_auc score of 0.56\n",
        "confusion matrix: \n",
        "[[4868  444]\n",
        " [1757  458]]\n",
        "BernoulliNB had an average accuracy score of 0.66, and roc_auc score of 0.61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "confusion matrix: \n",
        "[[3839 1486]\n",
        " [1083 1121]]\n",
        "GSD had an average accuracy score of 0.64, and roc_auc score of 0.63"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "confusion matrix: \n",
        "[[3498 1819]\n",
        " [ 879 1332]]\n",
        "Logistic had an average accuracy score of 0.73, and roc_auc score of 0.60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "confusion matrix: \n",
        "[[4859  459]\n",
        " [1587  622]]\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-c1ea7991bb1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-12-33bd832357a0>\u001b[0m in \u001b[0;36mtest_classifiers\u001b[1;34m(X, Y, times)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_roc_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"%s had an average accuracy score of %0.2f, and roc_auc score of %0.2f\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_roc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"confusion matrix: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-11-63261329ae90>\u001b[0m in \u001b[0;36mrunClassifier\u001b[1;34m(X, Y, clf, times)\u001b[0m\n\u001b[0;32m      8\u001b[0m          \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                             test_size=.2)\n\u001b[1;32m---> 10\u001b[1;33m          \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m          \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/randomized_l1.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             sample_fraction=self.sample_fraction, **params)\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscores_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/randomized_l1.pyc\u001b[0m in \u001b[0;36m_resample_model\u001b[1;34m(estimator_func, X, y, scaling, n_resampling, n_jobs, verbose, pre_dispatch, random_state, sample_fraction, **params)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 **params)\n\u001b[1;32m---> 52\u001b[1;33m             for _ in range(n_resampling)):\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mscores_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mactive_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \"\"\"\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/randomized_l1.pyc\u001b[0m in \u001b[0;36m_randomized_logistic\u001b[1;34m(X, y, weights, mask, C, verbose, fit_intercept, tol)\u001b[0m\n\u001b[0;32m    356\u001b[0m         clf = LogisticRegression(C=this_C, tol=tol, penalty='l1', dual=False,\n\u001b[0;32m    357\u001b[0m                                  fit_intercept=fit_intercept)\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         this_scores[:] = np.any(\n\u001b[0;32m    360\u001b[0m             np.abs(clf.coef_) > 10 * np.finfo(np.float).eps, axis=0)\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    701\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                                               rnd.randint(np.iinfo('i').max))\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Confusion matrix:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "<img src = 'https://computersciencesource.files.wordpress.com/2010/01/conmat.png' / >"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Try to reduce dimentions using pca"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "from sklearn.decomposition import SparsePCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sk_pca = PCA(n_components=200)\n",
      "sk_transf = sk_pca.fit_transform(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "explained_variance = [sk_pca.explained_variance_ratio_[0:i].sum() for i in range(200)]\n",
      "plot(range(200),explained_variance)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f3e0b437310>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGodJREFUeJzt3XucVOWd5/EPgmgUI+IFEBEQiQHjJV6QjZrUCEkwF9Co\nQUYTNRlDNkGz2cmEYdysPTOvTER3Mk7ia5VRJnF1DDEm3iaIi4llRkauq6jc5CKGqxeiiUqDdHft\nH79qu2i6qeqmrqc+79frvPpUndOnnhwrX55+nuc8D0iSJEmSJEmSJEmSJEmSJNWt8cAqYA0wrYPj\nRwAPAsuAhcDJ5SuaJKm7egJrgaHAgcBzwMh259wCfC+7fxLwRLkKJ0nq3AF5jo8mAn4DsBuYDUxs\nd85I4Mns/mriH4Oji1ZCSVK35Av4QcDGnNebsu/lWgZ8Ibs/GhgCHFeU0kmSui1fwGcKuMZNQF/g\nWWBq9mfzfpZLkrSfeuU5vhkYnPN6MFGLz/U28JWc1y8D69tfaPjw4Zl169Z1p4ySVM/WASd25xd7\n5Dnei2hXHwtsARYBk4GVOeccDjQC7wHXAucCV3dwrUwmU8gfBCpEQ0MDDQ0NlS5GIngvi6ue72cm\nA6+9Br//PbzyStuW+3rnThgyJLbjj2/7efzxMHgwDBoEBx3Uds0ePXpA/qzuUL4afBPR7PI4MaJm\nFhHuU7LHZwKjgJ8SzTkvAl/tTkEkqdo1N8OmTbBhQ8cB/vvfw6GH7hngw4ZBKtX2+qijoEe34rrr\n8gU8wGPZLdfMnP1niOGRklTTMhl4801Yvx5efjl+5u5v3AjHHNMW4EOGwNlnw6WXxv7gwdCnT6X/\nV7QpJOBVhVKpVKWLkBjey+Kq9vu5a1fUttuHd+t+JgMnnBDbsGFw2mlw8cWxP2QIHHxwpf8XFK5M\nfygAtsFLKpN334W1a2Nbsya2tWsjxF97DY47bs8Qb90/4QQ44ojyNaEUYn/a4A14STVpx462AG8f\n5H/4Q4T1iBFw4oltP4cPj3DvVUNtFwa8pERqbOw8xLdvj9r3iBF7BvmIERHiB+R7yqdGGPCSatrr\nr8OqVW3bypXxc+tWGDq0Lbhzg/y446Bnz0qXvPQMeElVr7k5hhe2hnfu1twMI0fChz/cto0cGTX0\nWmpOKQUDXlLVaGzcsxbe+nPtWujff88Ab90/5pjq6tisJga8pLLbvTvaw198cc9t48bozBw1as8Q\n/9CH4iEgdY0BL6lkWlpifHhuiC9fHuE+eDB85CNt28knR/t4796VLnVyGPCS9lsmA5s3twV4a5iv\nWBGP17cP8pEj4QMfqHSpk8+Al9Qlu3ZFcC9b1rY99xwceCCcckpbiH/kI9HUcvjhlS5x/TLgJXXq\n9df3DPFly6J5ZfjweAw/dxswoNKlVXsGvCSamyO4W0O8NdB37IjwPv30tiA/+eTamlOlnhnwUp1p\naoqhh0uXxrZkCTz/fNTAc2vkp58eU9Q6BLF2GfBSgjU3t4X5kiXxc9kyOPZYOOssOPPM2D76UdvK\nk8iAlxKiuRlWr24L8qVLo5ll4MC2MD/rLMO8npQ64McDtxIrOt0FzGh3/CjgXmAAMb/8/yJWeGrP\ngJfa2bIFFi6MbcGCCPT+/fcO8759K11SVUopA74nsSbrOGIB7sXsvSZrA3AQMJ0I+9VAf2K5v1wG\nvOpaY2MEeGuYL1wY85afc05sY8bE6kD9+lW6pKompVyTdTSwFtiQfT0bmMieAb8VODW7/0FgO3uH\nu1RXMpkY0dIa5AsWxJwsJ58cYT5xIvzDP8TMiHaAqlTyBfwgYGPO603AOe3OuRP4LbAFOAz4YtFK\nJ9WInTujdv700zB/Pvznf8a8K2PGxHbFFdHU4pOfKqd8AV9Im8rfAM8BKWA4MA84DXi7/YkNDQ3v\n76dSqapfu1HqzBtvRIi3Bvpzz8Wj++eeC1deCbffDoMGVbqUqkXpdJp0Ol2Ua+X743AM0cY+Pvt6\nOtDCnh2tc4DvA/Ozr38DTAOWtLuWbfCqSa3NLfPnx/b007EQxZgxEejnnhvNLn36VLqkSqJStsEv\nAUYAQ4kmmElEJ2uuVUQn7Hyic/UkYH13CiNVg5aWmGzrqadi+93v4qnP1jCfOjXma6mH1YRU2wr5\nV+FC2oZJzgJ+AEzJHptJjJz5CXA8cED2+H0dXMcavKpSS0s8BZob6H37wic+AalU/Dz++EqXUvXK\nB52kLmhujjbzp56CdDqaXI4+es9At/1c1cKAl/ahpSXmNX/iCfjtbyPQjz02grx1Gziw0qWUOmbA\nS+288koE+hNPwG9+Ax/8IIwbBxdcEIHev3+lSygVxoBX3du+HZ58si3U//QnGDs2Qn3sWBg6tNIl\nlLrHgFfdaWyMppbWGvpLL8F550WgjxsXKxEdcEClSyntPwNedWHtWnjssdj+4z/g1FPbAv2cc1zo\nWclkwCuRGhtjpMtjj8GcOfDOO3DhhbF98pPOsKj6YMArMdatawv0p5+OVYlaQ/30052YS/XHgFfN\n2rUraulz5sT29tswfjx85jPR9HLEEZUuoVRZBrxqyvbtEeaPPALz5sUUup/9bNTSTzvNzlEplwGv\nqrdmTQT6I4/EU6Rjx8KECVFTP+aYSpdOql4GvKpOc3MsdNEa6m+9BZ//fIT6BRc4L7pUKANeVeG9\n92JM+gMPwKOPxuP/EybEduaZNr1I3WHAq2J27ox29NZQHzUKLrkELroIhg2rdOmk2mfAq6waG2Hu\n3Aj1OXOiY/TSS+Hii52FUSo2A14l19gIv/41/OIX8PjjcNZZEeoXXQQDBlS6dFJyGfAqiaammF73\nvvvg4Ycj1CdNgokTY/50SaVX6oAfT9uKTnex53qsAN8Brsju9wJGEqs8vdXuPAO+BmQysGhRhPrP\nfx4rGV1xBXzxi86ZLlVCKQO+J7CaWHN1M7CYWJN1ZSfnfw74b9nz2zPgq9iqVRHq990Xa41ecQVM\nngwjRlS6ZFJ9K+Wi26OBtcCG7OvZwEQ6D/g/B37WnYKo/LZubQv1bdvg8suj1n7GGc75IiVBvoAf\nBGzMeb0JOKeTcw8BPg18owjlUons2hUPHv30p/DMMzHy5ZZbYpWjnj0rXTpJxZQv4LvSpvJ54Gn2\nbnt/X0NDw/v7qVSKVCrVhcuruzIZWLo0Qn327BjWeM01cP/9cOihlS6dpFzpdJp0Ol2Ua+X7Q3wM\n0EB0tAJMB1rYu6MV4EHg50QzTkdsgy+zV1+Fe++NYH/3Xbj6arjqKhgypNIlk1SoUnay9iI6WccC\nW4BFdNzJejiwHjgOaOzkWgZ8GTQ1xXj1WbPgd7+LcerXXAPnn+9UAVItKmUnaxMwFXicGFEziwj3\nKdnjM7M/L8qe01m4q8Q2bYK77ort+OPh2mvh3/4NDjus0iWTVCk+6FTDmpvjqdKZM2ON0smTYcqU\nWKtUUjKUsgavKrRtWzTB3HlnPFE6ZUrU1vv0qXTJJFUTA76GLFkCt94abeyXXQa//GVMwytJHbGJ\npso1NcFDD0Wwb9wI110HX/2qa5VK9cImmgR6881ohvnxj6PT9Nvfjkm+evlfTFKBjIsqs3o1/OhH\nMX3A5z4XzTBnnVXpUkmqRQZ8Fchk4OmnYcYMWLwYvvY1WL4cjj220iWTVMsM+ArKZKLD9Ac/iKdO\nv/vdWFDDBaklFYMBXwFNTTEPzE03xdOl06fH6khO9iWpmAz4Mtq9O+aFuemmWLt0xgwYP96peSWV\nhgFfBs3N8SDS3/4tnHAC3H03nHdepUslKekM+BJqaYEHHoAbb4Sjjophj86QLKlcDPgSyGTg0Ufh\ne9+D3r3jIaVPfcqmGEnlZcAX2bx5cMMNsHMn/P3fw4QJBrukyjDgi+SFF+A734GXX45gv+wy51+X\nVFlG0H7ati3mXh87Fj77WXjxRZg0yXCXVHnGUDft2BE19ZNPhr59Y4qB66+PNndJqgaFBPx4YBWw\nBpjWyTkp4FngRSBdjIJVq0wG7rkHTjopauuLF8Mttzi7o6Tqk6/7ryexJus4YDOwmL3XZO0LzAc+\nDWwCjgLe6OBaNT9d8LJlMHUqNDbGhGAf+1ilSyQp6fZnuuB8NfjRwFpgA7AbmA1MbHfOnwO/JMId\nOg73mvbWW/Ctb8EnPwlXXgkLFxrukqpfvoAfBGzMeb0p+16uEUA/4ElgCfClopWuwjIZuPdeGDUq\nau0rVsTyeM4ZI6kW5BsmWUibyoHAGcBY4BDgGWAB0Wa/h4aGhvf3U6kUqSp+rHP9evj61+GNN2JF\npdGjK10iSfUgnU6TTqeLcq187TpjgAaioxVgOtACzMg5Zxrwgex5AHcBc4EH2l2rJtrgm5rghz+E\nm2+GadNiJSVXUZJUKaVcsm8J0QQzFNgCTCI6WXM9DNxGdMgeBJwD/LA7ham0pUvhL/4i5o1ZtCgm\nBpOkWpUv4JuAqcDjRIDPIkbQTMken0kMoZwLPE/U7u8EVpSisKWyezd8//tw++0x5PFLX3J6AUm1\nr5wxVpVNNCtXRqAffXTM9ugyeZKqSSmHSSZWSwv80z/Bxz8eUw3MmWO4S0qWuuw+fP11mDw5Znxc\nsACGD690iSSp+OquBr90KZx9dmxPPWW4S0quuqrB3313TOl7xx1wySWVLo0klVZdBHxLC0yfDr/6\nFaTTMQOkJCVd4gN+50748pdhy5Zobz/yyEqXSJLKI9Ft8G+8EQtxHHAAPPGE4S6pviQ24DdvjiGQ\n554L990HBx9c6RJJUnklMuDXr4fzz4erroo5ZVw+T1I9Slz0LV8eNfe/+quYLEyS6lWipipYvx7O\nOy9q7VdeWdKPkqSy2J+pChIT8Nu3xypL118P3/xmyT5Gksqq7gO+sRHGjYva+4wZ+c+XpFpR1wHf\n0gKXXQYHHRTL69mhKilJSrngR9W78caYPGzePMNdknIVEonjiUU91hDL87WXAv4IPJvd/kexCpfP\ngw/G/DK/+EXU4CVJbfLV4HsSy/GNAzYDi4FHiFWdcj0FTCh66fZh5UqYMgV+/Wvo37+cnyxJtSFf\nDX40sBbYAOwGZgMTOzivrAvc/fGPcNFFMRzy7LPL+cmSVDvyBfwgYGPO603Z93JlgI8By4A5wKii\nla4TU6fCBRfA1VeX+pMkqXbla6IpZNjL/wMGAzuAC4GHgA/tZ7k6NXcuzJ8PL7xQqk+QpGTIF/Cb\nifBuNZioxed6O2f/MeB/A/2AP7S/WENDw/v7qVSKVCpVeEmBd96Br38d7rwTDj20S78qSTUhnU6T\nTqeLcq18bee9gNXAWGALsAiYzJ6drP2B14ja/mjgfmBoB9fa73Hw06bFvO733LNfl5GkmlHKcfBN\nwFTgcWJEzSwi3Kdkj88ELgX+a/bcHcDl3SlIPsuXw09+YtOMJBWqJp5kzWQglYJJk+Ab3yhuoSSp\nmu1PDb4mnv289154990Y9y5JKkzV1+DfegtGjoSHH4bRo0tQKkmqYomebOzb347ZIu+4owQlkqQq\nl9iAf+UVOOMMWLHC6Qgk1afEBvw118DgwfB3f1eiEklSlUvkdMHLl8OcOfDSS5UuiSTVpqodRXPD\nDfFg0+GHV7okklSbqrKJ5plnYsz7Sy/BwQeXuFSSVMUSNw7+hhugocFwl6T9UXU1+KVL4eKLYf16\n6FW1PQSSVB6JqsH/8z/HfO+GuyTtn6qqwW/dCqNGwbp10K9fmUolSVUsMTX4mTPh8ssNd0kqhqqp\nwTc3w9Ch8O//DqedVr5CSVI1S0QNfu5cGDjQcJekYqmagL/rLrj22kqXQpKSo5CAHw+sAtYA0/Zx\n3tnEqk5f6Gohtm2DdDra3yVJxZEv4HsCtxEhP4pYj3VkJ+fNAObSjbai+++HCRPgsMO6+puSpM7k\nC/jRwFpgA7AbmA1M7OC864AHgNe7U4jZs2Hy5O78piSpM/kCfhCwMef1pux77c+ZCNyefd2lOYE3\nbIA1a2Ds2K78liQpn3wBX0hY3wr8dfbcHnSxieb+++ELX4ADD+zKb0mS8sk3IcBmYHDO68FELT7X\nmUTTDcBRwIVEc84j7S/W0NDw/n4qlSKVSnH//XDzzV0rtCQlVTqdJp1OF+Va+WrbvYDVwFhgC7CI\n6Ghd2cn5PwEeBX7VwbG9HnR6551Yiu/NN6F3764UW5LqQylXdGoCpgKPEyNlZhHhPiV7fGZ3PrTV\nkiVw6qmGuySVQkWnKpgxIyYYu/XWMpZCkmpIzU5VsGABjBlTyRJIUnJVLOAzGVi4EM45p1IlkKRk\nq1jAb9oETU0xg6QkqfgqFvCttfce5ewFkKQ6UrGAX7wYRo+u1KdLUvJVLOCXL4dTTqnUp0tS8lUs\n4FesiPVXJUmlUZFx8Dt2wJFHwttvQ698j1pJUh2ruXHwq1fDiBGGuySVUkUC3uYZSSq9igX8yI7W\nhZIkFY01eElKKANekhKq7KNodu2Cww+HP/3JaYIlKZ+aGkWzZk3MP2O4S1JplT3gN26EIUPK/amS\nVH8KCfjxwCpgDTCtg+MTgWXAs8BS4IJ9XWzrVhg4sIullCR1Wb5HjXoCtwHjiAW4FxOLaeeuyfoE\n8HB2/xTgQeDEzi64ZQsce2x3iytJKlS+GvxoYC2wAdgNzCZq7LnezdnvA7yxrwtag5ek8sgX8IOA\njTmvN2Xfa+8iolb/GHD9vi5owEtSeeRrosnkOd7qoex2PnAPcFJHJzU0NLBoEfTtC0cdlSKVShVc\nUEmqB+l0mnQ6XZRr5RtbOQZoIDpaAaYDLcCMffzOOqJpZ3u79zOZTIYhQyCdhmHDul5YSao3pRwH\nvwQYAQwFegOTiE7WXMNzPvyM7M/24Q7EQtvbttlEI0nlkK+JpgmYCjxOjKiZRbS1T8kenwlcAnyZ\n6IR9B7i8s4v94Q9wyCFw8MH7WWpJUl5lnarg+eczTJoUc9FIkvKrmakKtm51DLwklUvZA972d0kq\nDwNekhKqrAG/ZYsBL0nlYhu8JCWUTTSSlFBlDfht22DAgHJ+oiTVr7IG/LvvQp8+5fxESapfZQ34\nXbtcqk+SyqWsAf/ee3DQQeX8REmqX2WvwRvwklQeZZ2LpkePDM3N0KOcnypJNaxm5qLp3dtwl6Ry\nKXvAS5LKo6wBb/u7JJWPAS9JCVVowI8HVgFrgGkdHL8CWAY8D8wHTu3oIga8JJVPviX7IJbquw0Y\nB2wGFhPrsq7MOWc98HHgj8Q/Bv9CLNi9BwNeksqnkBr8aGAtsIFYd3U2MLHdOc8Q4Q6wEDiuowvZ\nySpJ5VNIwA8CNua83pR9rzNfBeZ0dMAavCSVTyFNNJkuXO/PgK8A53Z0cNu2BhoaYj+VSpFKpbpw\naUlKvnQ6TTqdLsq1CnnsaAzQQLStA0wHWoAZ7c47FfhV9ry1HVwnM25chnnzuldQSapHpX6SdQkw\nAhgK9AYmEZ2suY4nwv1KOg53wDZ4SSqnQppomoCpwOPEiJpZxAiaKdnjM4H/CRwB3J59bzfRObsH\n2+AlqXzKOtnY5Zdn+NnPyviJklTjamayMWvwklQ+BrwkJZSzSUpSQlmDl6SEMuAlKaEMeElKKANe\nkhLKTlZJSihr8JKUUAa8JCWUAS9JCWXAS1JC2ckqSQllDV6SEsqAl6SEMuAlKaEKDfjxwCpgDTCt\ng+MfBp4BdgJ/2dlFDHhJKp9CluzrCdwGjAM2A4uJNVlX5pyzHbgOuGhfF7KTVZLKp5Aa/GhiIe0N\nxFqrs4GJ7c55nVice/e+LmQNXpLKp5CAHwRszHm9KftelxnwklQ+hTTRZIr1YT/+cQN9+sR+KpUi\nlUoV69KSlAjpdJp0Ol2UaxWyUvcYoIHoaAWYDrQAMzo490bgHeAfOziW2b49Q79+3SilJNWpHj16\nQGFZvZdCmmiWACOAoUBvYBLRydphWfZ1IZtoJKl8Cv1X4ULgVmJEzSzgB8CU7LGZwABidM0Hidr9\n28AoojbfKrN7d4ZehTQKSZKA/avBd+uXuimTyRStOV+S6kKpm2gkSTXIgJekhDLgJSmhDHhJSigD\nXpISyoCXpIQy4CUpoQx4SUooA16SEsqAl6SEMuAlKaEMeElKKANekhLKgJekhDLgJSmhCgn48cAq\nYA0wrZNzfpQ9vgz4aHGKJknaH/kCvidwGxHyo4DJwMh253wGOJFY1u9rwO1FLqM6UKxFeeW9LDbv\nZ/XIF/CjgbXABmA3MBuY2O6cCcDd2f2FQF+gf/GKqI74f6Li8V4Wl/ezeuQL+EHAxpzXm7Lv5Tvn\nuP0vmiRpf+QL+EIXUW2/XqCLr0pSheVbyHUM0EC0wQNMB1qAGTnn3AGkieYbiA7ZTwCvtrvWWmB4\n94sqSXVpHdHPWXS9shcfCvQGnqPjTtY52f0xwIJSFESSVHwXAquJGvj07HtTslur27LHlwFnlLV0\nkiRJkoqrkAeltG8bgOeBZ4FF2ff6AfOAl4D/SwxPVcf+legTeiHnvX3dv+nE93UV8KkylbFWdHQv\nG4jRc89mtwtzjnkv920w8CSwHHgRuD77fk18P3sSTTdDgQPpuA1f+b1M/AfPdTPw3ez+NOCmspao\ntpxPPGGdG0qd3b9RxPf0QOJ7uxan9MjV0b28EfjvHZzrvcxvAHB6dr8P0Rw+khr5fv4XYG7O67/O\nbuqal4Ej2723irYHygZkX6tzQ9kzlDq7f9PZ8y/NucTgAbUZyt4B/5cdnOe97LqHgHEU6ftZ6uQv\n5EEp5ZcBngCWANdm3+tP21DUV/Hp4a7q7P4dS3xPW/mdLcx1xCCLWbQ1J3gvu2Yo8dfRQor0/Sx1\nwPvAU3GcS/yHvxD4JvFncq4M3uv9ke/+eW/37XZgGNHUsBX4x32c673sWB/gl8C3gLfbHev297PU\nAb+Z6ERoNZg9//VRYbZmf74OPEjMEfQq8acbwEDgtQqUq5Z1dv/af2ePy76nzr1GWwjdRXw/wXtZ\nqAOJcL+HaKKBIn0/Sx3wS4hZJocSD0pNAh4p8WcmzSHAYdn9Q4le8xeI+3hV9v2raPtiqDCd3b9H\ngMuJ7+sw4vu7aK/fVq6BOfsX09Y+773MrwfRrLUCuDXn/Zr5fnb0oJQKN4zoNX+OGEbVeg/7Ee3y\nDpPM72fAFuA9ok/oGvZ9//6G+L6uAj5d1pJWv/b38ivA/yGG8S4jgii3P8h7uW/nEdO/PEfbMNPx\n+P2UJEmSJEmSJEmSJEmSJEmSJEmSlBT/H7OIxGAUk/LYAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f3e0b5ec790>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_classifiers(sk_transf, y,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
        "  VisibleDeprecationWarning)\n",
        "-c:15: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RandomForest had an average accuracy score of 0.70, and roc_auc score of 0.55\n",
        "confusion matrix: \n",
        "[[4819  515]\n",
        " [1758  436]]\n",
        "BernoulliNB had an average accuracy score of 0.67, and roc_auc score of 0.58"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "confusion matrix: \n",
        "[[4287 1044]\n",
        " [1415  782]]\n",
        "GSD had an average accuracy score of 0.68, and roc_auc score of 0.58"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "confusion matrix: \n",
        "[[4376  951]\n",
        " [1454  747]]\n",
        "Logistic had an average accuracy score of 0.74, and roc_auc score of 0.60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "confusion matrix: \n",
        "[[4951  401]\n",
        " [1575  600]]\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'RandomizedLogisticRegression' object has no attribute 'predict'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-29-a1b0e6220d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msk_transf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-28-33bd832357a0>\u001b[0m in \u001b[0;36mtest_classifiers\u001b[1;34m(X, Y, times)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_roc_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"%s had an average accuracy score of %0.2f, and roc_auc score of %0.2f\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_roc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"confusion matrix: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-27-63261329ae90>\u001b[0m in \u001b[0;36mrunClassifier\u001b[1;34m(X, Y, clf, times)\u001b[0m\n\u001b[0;32m     10\u001b[0m          \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m          \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m          \u001b[0msum_scores_roc_auc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m          \u001b[0msum_scores\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedLogisticRegression' object has no attribute 'predict'"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for name, clf in classifiers.items():\n",
      "    score,score_auc,y_hat = runSingleClassifier(sk_transf_X, y_train, X_test, y_test, clf)\n",
      "    print score, score_auc\n",
      "    print metrics.confusion_matrix(y_test, y_hat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.696374020454 0.553719546153\n",
        "[[4800  464]\n",
        " [1822  443]]\n",
        "0.638995882587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.593930785644\n",
        "[[3722 1542]\n",
        " [1176 1089]]\n",
        "0.719750298844"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.59546425552\n",
        "[[4777  487]\n",
        " [1623  642]]\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Optimize models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ModelTester:\n",
      "    def __init__(self, x, y):\n",
      "        self.models = []\n",
      "    \n",
      "        (x_train, x_test,\n",
      "         y_train, y_test) = cv.train_test_split(x, y,\n",
      "                                        test_size=.2)\n",
      "        self.x_train = x_train\n",
      "        self.x_test = x_test\n",
      "        self.y_train = y_train\n",
      "        self.y_test = y_test\n",
      "        \n",
      "        \n",
      "    def add_model(self, name, model, param_grid={}):\n",
      "        optimized_model = gs.GridSearchCV(model, param_grid)        \n",
      "        optimized_model.fit(self.x_train, self.y_train)\n",
      "        data = {\n",
      "            'name':name,           \n",
      "            'model': optimized_model\n",
      "        }\n",
      "        self.models.append(data)\n",
      "        \n",
      "    def test_models(self):\n",
      "        for model in self.models:\n",
      "            score = model['model'].score(self.x_test, self.y_test)\n",
      "            print \"%s: \" % model['name'] \n",
      "            print \"------------------------\"\n",
      "            print \"score: %s\" % (score)\n",
      "            print \"best estomator: \" ,model['model'].best_estimator_\n",
      "            print \"best params: \" , model['model'].best_params_\n",
      "            print \"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modeltester= ModelTester(sk_transf, y)\n",
      "modeltester.add_model(\"BernoulliNB\",BernoulliNB(),param_grid={'alpha':np.logspace(-2., 2., 50)} )\n",
      "#modeltester.add_model(\"LogisticRegression\",LogisticRegression(),param_grid={'C':range(1,600,20)}) ## result was c=1\n",
      "modeltester.test_models()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB: \n",
        "------------------------\n",
        "score: 0.677513614026\n",
        "best estomator:  BernoulliNB(alpha=82.864277285468418, binarize=0.0, class_prior=None,\n",
        "      fit_prior=True)\n",
        "best params:  {'alpha': 82.864277285468418}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(X_train, X_test,\n",
      " y_train, y_test) = cv.train_test_split(x, y,\n",
      "                                        test_size=.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg = lm.LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_p = logreg.predict(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_predicted = logreg.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Todo: Display how many false positive & false negative  we have in the one's"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SandBox:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame = pd.DataFrame(randn(20, 3), columns=['a', 'b', 'c'])\n",
      "frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>a</th>\n",
        "      <th>b</th>\n",
        "      <th>c</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>-0.673991</td>\n",
        "      <td> 0.620540</td>\n",
        "      <td>-1.123986</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.190817</td>\n",
        "      <td> 1.016182</td>\n",
        "      <td>-0.630691</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>-0.592813</td>\n",
        "      <td>-0.133895</td>\n",
        "      <td> 0.563608</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>-0.071942</td>\n",
        "      <td> 0.264087</td>\n",
        "      <td> 0.115671</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.492744</td>\n",
        "      <td> 0.262875</td>\n",
        "      <td>-0.525577</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.671756</td>\n",
        "      <td>-0.303179</td>\n",
        "      <td>-0.055996</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.259892</td>\n",
        "      <td> 0.229084</td>\n",
        "      <td> 0.964229</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 1.858884</td>\n",
        "      <td>-0.351517</td>\n",
        "      <td> 0.262541</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.546087</td>\n",
        "      <td> 0.864349</td>\n",
        "      <td> 0.604243</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>-2.125984</td>\n",
        "      <td>-0.146772</td>\n",
        "      <td> 0.615620</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 1.985864</td>\n",
        "      <td>-0.645557</td>\n",
        "      <td>-0.367971</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0.337947</td>\n",
        "      <td> 2.549516</td>\n",
        "      <td>-0.242727</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>-0.037513</td>\n",
        "      <td> 1.122487</td>\n",
        "      <td> 0.540087</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>-0.428719</td>\n",
        "      <td> 1.174969</td>\n",
        "      <td> 0.923297</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>-0.524233</td>\n",
        "      <td> 1.084213</td>\n",
        "      <td>-1.228476</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>-0.920840</td>\n",
        "      <td> 0.025136</td>\n",
        "      <td> 0.965158</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 0.870421</td>\n",
        "      <td>-0.173694</td>\n",
        "      <td>-1.116824</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>-1.457525</td>\n",
        "      <td> 0.857418</td>\n",
        "      <td>-0.847202</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>-0.219143</td>\n",
        "      <td> 0.348314</td>\n",
        "      <td>-0.048326</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>-1.369048</td>\n",
        "      <td>-1.459860</td>\n",
        "      <td>-0.153525</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "           a         b         c\n",
        "0  -0.673991  0.620540 -1.123986\n",
        "1   0.190817  1.016182 -0.630691\n",
        "2  -0.592813 -0.133895  0.563608\n",
        "3  -0.071942  0.264087  0.115671\n",
        "4   0.492744  0.262875 -0.525577\n",
        "5   0.671756 -0.303179 -0.055996\n",
        "6   0.259892  0.229084  0.964229\n",
        "7   1.858884 -0.351517  0.262541\n",
        "8   0.546087  0.864349  0.604243\n",
        "9  -2.125984 -0.146772  0.615620\n",
        "10  1.985864 -0.645557 -0.367971\n",
        "11  0.337947  2.549516 -0.242727\n",
        "12 -0.037513  1.122487  0.540087\n",
        "13 -0.428719  1.174969  0.923297\n",
        "14 -0.524233  1.084213 -1.228476\n",
        "15 -0.920840  0.025136  0.965158\n",
        "16  0.870421 -0.173694 -1.116824\n",
        "17 -1.457525  0.857418 -0.847202\n",
        "18 -0.219143  0.348314 -0.048326\n",
        "19 -1.369048 -1.459860 -0.153525"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = df.corr().abs()\n",
      "\n",
      "s = c.unstack()\n",
      "so = s.order(kind=\"quicksort\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame = pd.DataFrame(randn(20, 3), columns=['a', 'b', 'c'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "td = frame.ix[:,(frame != 0).any(axis=0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "y_hat_a = pd.Series(data=[0,1,1,1,0])\n",
      "m = metrics.confusion_matrix(y_a, y_hat_a)\n",
      "\n",
      "print m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Found array with dim 5. Expected 100",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-59-4a4b38a963e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_hat_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.pyc\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m     \"\"\"\n\u001b[1;32m--> 959\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_clf_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.pyc\u001b[0m in \u001b[0;36m_check_clf_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_lists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             raise ValueError(\"Found array with dim %d. Expected %d\"\n\u001b[1;32m--> 254\u001b[1;33m                              % (size, n_samples))\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_lists\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Found array with dim 5. Expected 100"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [[randint(2) for j in range(0,5)] for i in range(0,3)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a = pd.DataFrame(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "   0  1  2  3  4\n",
        "0  0  0  0  1  0\n",
        "1  1  0  1  1  0\n",
        "2  0  0  0  0  0"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a.pop(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0    0\n",
        "1    1\n",
        "2    0\n",
        "Name: 0, dtype: int64"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "   1  2  3  4\n",
        "0  0  0  1  0\n",
        "1  0  1  1  0"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "1    0\n",
        "2    1\n",
        "3    2\n",
        "4    0\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_a = df_a.drop([49], axis=1)\n",
      "y_a = df_a[49]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sk_pca_a = PCA(n_components=None)\n",
      "sk_transf_a = sk_pca.fit_transform(x_a)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_a = df_a.sum(axis=1)\n",
      "plt.hist(s_a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "(array([  1.,   6.,   9.,  12.,  21.,  14.,  10.,  17.,   8.,   2.]),\n",
        " array([ 16. ,  17.7,  19.4,  21.1,  22.8,  24.5,  26.2,  27.9,  29.6,\n",
        "         31.3,  33. ]),\n",
        " <a list of 10 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkaZz+DySpEh3NfSLSAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fbca4dd63d0>"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a['a'] = df_a.sum(axis=1)\n",
      "df_a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>a</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "   0  1  2  a\n",
        "0  0  0  0  0\n",
        "1  1  0  0  1\n",
        "2  1  0  1  2\n",
        "3  0  1  1  2"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'DataFrame' object has no attribute 'value_counts'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-25-0d9b3bc6549d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1841\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 1843\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'value_counts'"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [[j for j in range(0,4)] for i in range(0,2)]\n",
      "df_a = pd.DataFrame(a)\n",
      "sum_df = df_a.sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "   0  1  2  3\n",
        "0  0  1  2  3\n",
        "1  0  1  2  3"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0    6\n",
        "1    6\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_a.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "0    0\n",
        "1    2\n",
        "2    4\n",
        "3    6\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Visualizaion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "def plot_coo_matrix(m):\n",
      "    if not isinstance(m, coo_matrix):\n",
      "        m = coo_matrix(m)\n",
      "    fig = plt.figure()\n",
      "    ax = fig.add_subplot(111, axisbg='black')\n",
      "    ax.plot(m.col, m.row, 's', color='white', ms=1)\n",
      "    ax.set_xlim(0, m.shape[1])\n",
      "    ax.set_ylim(0, m.shape[0])\n",
      "    ax.set_aspect('equal')\n",
      "    for spine in ax.spines.values():\n",
      "        spine.set_visible(False)\n",
      "    ax.invert_yaxis()\n",
      "    ax.set_aspect('equal')\n",
      "    ax.set_xticks([])\n",
      "    ax.set_yticks([])\n",
      "    return ax\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "shape = (100, 100)\n",
      "rows = np.int_(np.round_(shape[0]*np.random.random(10)))\n",
      "cols = np.int_(np.round_(shape[1]*np.random.random(10)))\n",
      "vals = np.ones_like(rows)\n",
      "\n",
      "m = coo_matrix((vals, (rows, cols)), shape=shape)\n",
      "ax = plot_coo_matrix(m)\n",
      "ax.figure.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADtCAYAAABTTfKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAwNJREFUeJzt3UFug0AUBUGSi3D/Uyb7SA6KYg3Tn6qtN2xaFjDiHQcA\nAAAAAABxHxe/fy25CuCnl21+rrwK4P9ECzGihRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFGNFCjGgh\nRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa03OI8z+M8z7sv\nI0m0EGOfFvZknxamEC3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa0ECNa\niBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiJbHeff41+oxMdFCjAEu2JMBLphCtBAjWogRLcSI\nFmJECzGihYXecRBDtBDjcAXsyeEKmEK0LLX6cP1EooUY97SwJ/e0MIVoIUa0ECNaiBEtxIgWYkQL\nMaKFGNFCjGghRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxoIUa0\nD2H4ag7RQowBLtiTAS6YQrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjR\nQoxoIUa0ECNaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiBZitorWhipc2ypa4Jp9WtiTfVqY\nQrQQI1qIES3c7K9vTUQLMZ4ew548PYYpRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGihRjRQoxo\nIUa0ECNaiBEtxIgWYkTL49SXLEQLMb4RBXvyjSiYQrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAj\nWogRLcSIFmJECzGihRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFGNFCzK/RlqcTYCr/tBBjFgT2ZBYE\nphAtxIgWYkQLMaKFGNFCjGghRrQQI1qIES3EiBZiRAsxooUY0UKMaCFGtBAjWogRLcSIFmJECzGi\nhRjRQoxoIUa0ECNaiBEtxIgWYkQLMaKFGNFCjGghRrQQI1qIES0AAAAAAADAWt8DcxKcEsrrbQAA\nAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f9bd9a3bd10>"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "array([54, 40, 48, 21, 32,  2, 14,  4, 20, 83])"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}